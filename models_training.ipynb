{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "import joblib\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.tbats import TBATS\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "\n",
    "from prophet import Prophet\n",
    "from orbit.models import DLT\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Настройки\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "sns.set_style('darkgrid')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0359a9c1",
   "metadata": {},
   "source": [
    "## Загрузка и разбиение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2071d504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружены обработанные данные для STORE_1: (27285, 13)\n",
      "\n",
      "Первые 5 строк:\n",
      "       item_id  date_id  cnt       date  wm_yr_wk    weekday  wday  month  year event_name_1 event_type_1  cashback  sell_price\n",
      "0  STORE_1_064        1    0 2011-01-29     11101   Saturday     1      1  2011      NoEvent       NoType         0        2.54\n",
      "1  STORE_1_064        2    1 2011-01-30     11101     Sunday     2      1  2011      NoEvent       NoType         0        2.54\n",
      "2  STORE_1_064        3    0 2011-01-31     11101     Monday     3      1  2011      NoEvent       NoType         0        2.54\n",
      "3  STORE_1_064        4    0 2011-02-01     11101    Tuesday     4      2  2011      NoEvent       NoType         0        2.54\n",
      "4  STORE_1_064        5    0 2011-02-02     11101  Wednesday     5      2  2011      NoEvent       NoType         1        2.54\n",
      "\n",
      "Информация о данных:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27285 entries, 0 to 27284\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   item_id       27285 non-null  object        \n",
      " 1   date_id       27285 non-null  int64         \n",
      " 2   cnt           27285 non-null  int64         \n",
      " 3   date          27285 non-null  datetime64[ns]\n",
      " 4   wm_yr_wk      27285 non-null  int64         \n",
      " 5   weekday       27285 non-null  object        \n",
      " 6   wday          27285 non-null  int64         \n",
      " 7   month         27285 non-null  int64         \n",
      " 8   year          27285 non-null  int64         \n",
      " 9   event_name_1  27285 non-null  object        \n",
      " 10  event_type_1  27285 non-null  object        \n",
      " 11  cashback      27285 non-null  int64         \n",
      " 12  sell_price    27285 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(7), object(4)\n",
      "memory usage: 2.7+ MB\n",
      "\n",
      "Проверка пропусков (на всякий случай):\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# --- Загрузка данных ---\n",
    "STORE_ID = 'STORE_1'\n",
    "processed_data_path = f'data/processed_{STORE_ID}_data.csv'\n",
    "df = pd.read_csv(processed_data_path, parse_dates=['date'])\n",
    "\n",
    "print(f\"Загружены обработанные данные для {STORE_ID}: {df.shape}\")\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "print(df.head())\n",
    "print(\"\\nИнформация о данных:\")\n",
    "df.info()\n",
    "print(\"\\nПроверка пропусков (на всякий случай):\")\n",
    "print(df.isnull().sum().sum()) # Должен быть 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a886a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Разбиение данных ---\n",
      "Дата разделения: 2015-10-24\n",
      "Размер обучающей выборки (train_df): (25935, 13)\n",
      "Временной диапазон train: 2011-01-29 - 2015-10-23\n",
      "Размер тестовой выборки (test_df): (1350, 13)\n",
      "Временной диапазон test: 2015-10-24 - 2016-01-21\n",
      "\n",
      "Уникальных дней в тесте на товар (min/max): 90/90\n"
     ]
    }
   ],
   "source": [
    "# --- Параметры прогнозирования ---\n",
    "FH_WEEK = 7\n",
    "FH_MONTH = 30\n",
    "FH_QUARTER = 90\n",
    "TEST_SIZE = FH_QUARTER # Размер тестовой выборки равен максимальному горизонту\n",
    "\n",
    "# --- Разбиение данных ---\n",
    "\n",
    "# Определяем точку разделения\n",
    "split_date = df['date'].max() - pd.Timedelta(days=TEST_SIZE -1) # -1 т.к. включительно\n",
    "\n",
    "# Создаем обучающую и тестовую выборки\n",
    "train_df = df[df['date'] < split_date].copy()\n",
    "test_df = df[df['date'] >= split_date].copy()\n",
    "\n",
    "print(f\"\\n--- Разбиение данных ---\")\n",
    "print(f\"Дата разделения: {split_date.date()}\")\n",
    "print(f\"Размер обучающей выборки (train_df): {train_df.shape}\")\n",
    "print(f\"Временной диапазон train: {train_df['date'].min().date()} - {train_df['date'].max().date()}\")\n",
    "print(f\"Размер тестовой выборки (test_df): {test_df.shape}\")\n",
    "print(f\"Временной диапазон test: {test_df['date'].min().date()} - {test_df['date'].max().date()}\")\n",
    "\n",
    "# Проверим, что в тесте ровно TEST_SIZE дней для каждого товара\n",
    "test_days_per_item = test_df.groupby('item_id')['date'].nunique()\n",
    "print(f\"\\nУникальных дней в тесте на товар (min/max): {test_days_per_item.min()}/{test_days_per_item.max()}\")\n",
    "if test_days_per_item.min() != TEST_SIZE or test_days_per_item.max() != TEST_SIZE:\n",
    "    print(\"ПРЕДУПРЕЖДЕНИЕ: Количество дней в тестовой выборке не совпадает с TEST_SIZE для некоторых товаров!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17144c9",
   "metadata": {},
   "source": [
    "**Выбор метрик для задачи:**\n",
    "\n",
    "*   **MAE и RMSE:** Хорошие основные метрики для оценки абсолютной ошибки в единицах товара. MAE более робастна, RMSE сильнее штрафует большие промахи. Будем использовать обе.\n",
    "*   **MAPE/sMAPE:** Из-за наличия нулевых продаж в данных, стандартный MAPE использовать рискованно. sMAPE является более безопасной альтернативой для оценки относительной ошибки.\n",
    "*   **R²:** Включим для общей информации, но не будем делать на нее основной упор.\n",
    "\n",
    "Создадим функцию для расчета этих метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab5ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Рассчитывает MAE, RMSE, sMAPE и R2.\"\"\"\n",
    "    # Убедимся, что нет NaN/inf в прогнозах, заменим их на 0 (или другое значение)\n",
    "    y_pred = np.nan_to_num(y_pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Расчет sMAPE с защитой от деления на ноль в знаменателе\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    # Избегаем деления на ноль, где и числитель, и знаменатель равны 0\n",
    "    smape = np.mean(np.divide(numerator, denominator, out=np.zeros_like(numerator, dtype=float), where=denominator!=0)) * 100\n",
    "    # Если нужно другое поведение при 0/0 (например, считать ошибку 0), можно изменить 'out'\n",
    "\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'sMAPE': smape,\n",
    "        'R2': r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b4951f",
   "metadata": {},
   "source": [
    "## Обучение стат. моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b07e84",
   "metadata": {},
   "source": [
    "### Наивный прогноз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a80ff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Baseline прогноз (Seasonal Naive, FH=90) ---\n",
      "\n",
      "--- Baseline метрики по горизонтам прогнозирования ---\n",
      "            Week      Month    Quarter\n",
      "MAE     5.180952   5.695556   7.934074\n",
      "RMSE    6.515400   7.371659  10.239756\n",
      "sMAPE  69.216369  70.952425  78.637057\n",
      "R2     -0.820453  -0.687139  -0.657725\n",
      "\n",
      "--- Метрики Baseline по товарам (Квартал) ---\n",
      "                   MAE       RMSE       sMAPE        R2\n",
      "item_id                                                \n",
      "STORE_1_064   0.211111   0.567646   33.333333 -0.160516\n",
      "STORE_1_065   0.733333   1.358103   94.920635 -0.215029\n",
      "STORE_1_090  44.422222  57.453750   95.936457 -0.581973\n",
      "STORE_1_252   7.644444   9.473941   46.762621 -0.520806\n",
      "STORE_1_325   4.244444   5.189733  105.340298 -0.346625\n",
      "STORE_1_339   3.200000   4.071582  121.984959 -1.272696\n",
      "STORE_1_376   0.711111   1.183216   89.888889 -0.254980\n",
      "STORE_1_546   1.855556   2.433562   76.023162 -0.446579\n",
      "STORE_1_547  13.266667  17.287761  146.038597 -1.043643\n",
      "STORE_1_555   7.988889  10.115445   33.589121 -0.532291\n",
      "STORE_1_584   1.466667   2.472066  113.232389 -0.205083\n",
      "STORE_1_586  11.188889  14.074800   33.932374 -0.534060\n",
      "STORE_1_587   8.588889  10.829486   29.674513 -0.477473\n",
      "STORE_1_714   9.155556  11.201190   41.617017 -1.453929\n",
      "STORE_1_727   4.333333   5.884065  117.281482 -1.820193\n"
     ]
    }
   ],
   "source": [
    "# --- Baseline: Сезонный наивный прогноз (сдвиг на 7 дней) ---\n",
    "\n",
    "def seasonal_naive_forecast(train_data, fh):\n",
    "    \"\"\"Генерирует сезонный наивный прогноз (сдвиг на 7 дней) для всех товаров.\"\"\"\n",
    "    forecasts = []\n",
    "    unique_items = train_data['item_id'].unique()\n",
    "    last_train_date = train_data['date'].max()\n",
    "\n",
    "    for item in unique_items:\n",
    "        item_train_data = train_data[train_data['item_id'] == item].set_index('date').sort_index()\n",
    "        # Берем последние 7 дней из трейна как основу для прогноза\n",
    "        last_week_values = item_train_data['cnt'].iloc[-7:].values\n",
    "\n",
    "        # Повторяем значения последней недели нужное количество раз\n",
    "        reps = int(np.ceil(fh / 7))\n",
    "        item_preds_raw = np.tile(last_week_values, reps)[:fh] # Берем только нужную длину fh\n",
    "\n",
    "        # Создаем индекс дат для прогноза\n",
    "        pred_dates = pd.date_range(start=last_train_date + pd.Timedelta(days=1), periods=fh, freq='D')\n",
    "\n",
    "        # Создаем DataFrame для прогноза этого товара\n",
    "        item_forecast_df = pd.DataFrame({\n",
    "            'date': pred_dates,\n",
    "            'item_id': item,\n",
    "            'yhat_baseline': item_preds_raw # Назовем прогноз 'yhat_baseline'\n",
    "        })\n",
    "        forecasts.append(item_forecast_df)\n",
    "\n",
    "    # Объединяем прогнозы для всех товаров\n",
    "    baseline_forecast_df = pd.concat(forecasts).reset_index(drop=True)\n",
    "    return baseline_forecast_df\n",
    "\n",
    "# Генерируем baseline прогнозы на тестовый период (90 дней)\n",
    "baseline_preds = seasonal_naive_forecast(train_df, FH_QUARTER)\n",
    "\n",
    "print(\"\\n--- Baseline прогноз (Seasonal Naive, FH=90) ---\")\n",
    "# print(baseline_preds.head())\n",
    "# print(baseline_preds.shape)\n",
    "\n",
    "# Оценка Baseline модели\n",
    "# Сначала объединим прогнозы с реальными значениями из test_df\n",
    "test_merged_baseline = pd.merge(test_df[['date', 'item_id', 'cnt']],\n",
    "                                baseline_preds,\n",
    "                                on=['date', 'item_id'],\n",
    "                                how='left')\n",
    "\n",
    "\n",
    "baseline_results_summary = {}\n",
    "min_test_date = test_merged_baseline['date'].min()\n",
    "\n",
    "# Горизонты для оценки\n",
    "horizons = {'Week': FH_WEEK, 'Month': FH_MONTH, 'Quarter': FH_QUARTER}\n",
    "\n",
    "# Рассчитываем метрики для каждого горизонта\n",
    "for name, days in horizons.items():\n",
    "    # Фильтруем данные для текущего горизонта\n",
    "    test_horizon = test_merged_baseline[test_merged_baseline['date'] < min_test_date + pd.Timedelta(days=days)]\n",
    "    # Считаем метрики по каждому товару и усредняем\n",
    "    horizon_metrics_df = test_horizon.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_baseline'])))\n",
    "    # Сохраняем средние значения\n",
    "    baseline_results_summary[name] = horizon_metrics_df.mean()\n",
    "\n",
    "# Создаем и выводим итоговую таблицу\n",
    "baseline_summary_df = pd.DataFrame(baseline_results_summary)\n",
    "\n",
    "print(\"\\n--- Baseline метрики по горизонтам прогнозирования ---\")\n",
    "print(baseline_summary_df)\n",
    "\n",
    "# Дополнительно: Вывод метрик по товарам для самого длинного горизонта (квартал)\n",
    "print(\"\\n--- Метрики Baseline по товарам (Квартал) ---\")\n",
    "baseline_metrics_quarter_df = test_merged_baseline.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_baseline'])))\n",
    "print(baseline_metrics_quarter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27374cdc",
   "metadata": {},
   "source": [
    "### Обучение и прогнозы AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38134c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Обучение AutoARIMA (sp=7) для 15 товаров ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6c711e82ca4143bea4b5bc93eaf50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Обучение AutoARIMA:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение AutoARIMA завершено.\n",
      "Общее время обучения: 525.08 сек.\n",
      "Успешно обучено моделей: 15 из 15\n",
      "Среднее время обучения на 1 модель: 35.00 сек.\n"
     ]
    }
   ],
   "source": [
    "# Обучение AutoARIMA\n",
    "\n",
    "# Словарь для хранения обученных моделей и времени обучения\n",
    "autoarima_models = {}\n",
    "autoarima_fit_times = {}\n",
    "\n",
    "print(f\"--- Обучение AutoARIMA (sp=7) для {len(train_df['item_id'].unique())} товаров ---\")\n",
    "start_total_fit_time = time.time()\n",
    "\n",
    "for item_id in tqdm(train_df['item_id'].unique(), desc=\"Обучение AutoARIMA\"):\n",
    "    start_item_fit_time = time.time()\n",
    "    # Готовим данные для sktime (Series с DatetimeIndex)\n",
    "    item_train_series = train_df[train_df['item_id'] == item_id].set_index('date')['cnt'].sort_index()\n",
    "\n",
    "    # Проверяем на наличие достаточного количества данных (хотя бы 2 сезона)\n",
    "    if len(item_train_series) < 2 * 7:\n",
    "        print(f\"Пропуск {item_id}: недостаточно данных ({len(item_train_series)} точек)\")\n",
    "        autoarima_models[item_id] = None\n",
    "        autoarima_fit_times[item_id] = None\n",
    "        continue\n",
    "\n",
    "    # Инициализируем модель AutoARIMA\n",
    "    # sp=7 для недельной сезонности\n",
    "    # suppress_warnings=True, чтобы избежать множества предупреждений от pmdarima\n",
    "    # error_action='ignore', чтобы пропустить ряды, где модель не сходится\n",
    "    forecaster = AutoARIMA(sp=7, suppress_warnings=True, error_action='ignore', maxiter=10) # maxiter можно увеличить, если нужно больше попыток\n",
    "\n",
    "    try:\n",
    "        forecaster.fit(y=item_train_series)\n",
    "        autoarima_models[item_id] = forecaster\n",
    "        end_item_fit_time = time.time()\n",
    "        autoarima_fit_times[item_id] = end_item_fit_time - start_item_fit_time\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка обучения AutoARIMA для {item_id}: {e}\")\n",
    "        autoarima_models[item_id] = None\n",
    "        autoarima_fit_times[item_id] = None\n",
    "\n",
    "end_total_fit_time = time.time()\n",
    "successful_fits = sum(1 for model in autoarima_models.values() if model is not None)\n",
    "print(f\"\\nОбучение AutoARIMA завершено.\")\n",
    "print(f\"Общее время обучения: {end_total_fit_time - start_total_fit_time:.2f} сек.\")\n",
    "print(f\"Успешно обучено моделей: {successful_fits} из {len(train_df['item_id'].unique())}\")\n",
    "\n",
    "# Можно посмотреть среднее время обучения на 1 товар\n",
    "valid_fit_times = [t for t in autoarima_fit_times.values() if t is not None]\n",
    "if valid_fit_times:\n",
    "    print(f\"Среднее время обучения на 1 модель: {np.mean(valid_fit_times):.2f} сек.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad6c9b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Генерация прогнозов AutoARIMA (на 90 дней) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0d15e24c244616996d9adb9c1f4a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Прогнозирование AutoARIMA:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Общее время прогнозирования AutoARIMA: 0.86 сек.\n",
      "Размер датафрейма прогнозов: (1350, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Прогнозирование и Оценка AutoARIMA\n",
    "\n",
    "# Список для хранения прогнозов\n",
    "autoarima_forecasts = []\n",
    "autoarima_predict_times = {}\n",
    "\n",
    "print(\"\\n--- Генерация прогнозов AutoARIMA (на 90 дней) ---\")\n",
    "start_total_predict_time = time.time()\n",
    "\n",
    "# Определяем горизонт прогнозирования для sktime\n",
    "# Это будут шаги относительно конца обучающей выборки\n",
    "fh = ForecastingHorizon(np.arange(1, FH_QUARTER + 1), is_relative=True)\n",
    "\n",
    "# Даты тестового периода (нужны для создания итогового DataFrame)\n",
    "test_start_date = test_df['date'].min()\n",
    "test_end_date = test_df['date'].max()\n",
    "pred_dates_index = pd.date_range(start=test_start_date, end=test_end_date, freq='D')\n",
    "\n",
    "\n",
    "for item_id, model in tqdm(autoarima_models.items(), desc=\"Прогнозирование AutoARIMA\"):\n",
    "    # Заготовка DataFrame для товара\n",
    "    item_forecast_df = pd.DataFrame({'date': pred_dates_index, 'item_id': item_id})\n",
    "\n",
    "    if model is not None:\n",
    "        start_item_predict_time = time.time()\n",
    "        try:\n",
    "            # Генерируем прогноз\n",
    "            y_pred = model.predict(fh=fh)\n",
    "            # Присваиваем правильные даты\n",
    "            y_pred.index = pred_dates_index\n",
    "            item_forecast_df['yhat_autoarima'] = y_pred.values\n",
    "\n",
    "            end_item_predict_time = time.time()\n",
    "            autoarima_predict_times[item_id] = end_item_predict_time - start_item_predict_time\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка прогнозирования AutoARIMA для {item_id}: {e}\")\n",
    "            item_forecast_df['yhat_autoarima'] = np.nan # Заполняем NaN при ошибке\n",
    "            autoarima_predict_times[item_id] = None\n",
    "    else:\n",
    "        item_forecast_df['yhat_autoarima'] = np.nan # Заполняем NaN, если модель не обучилась\n",
    "        autoarima_predict_times[item_id] = None\n",
    "\n",
    "    autoarima_forecasts.append(item_forecast_df)\n",
    "\n",
    "# Объединяем прогнозы\n",
    "autoarima_forecast_df = pd.concat(autoarima_forecasts).reset_index(drop=True)\n",
    "# Обрабатываем NaN и отрицательные значения\n",
    "autoarima_forecast_df['yhat_autoarima'] = autoarima_forecast_df['yhat_autoarima'].clip(lower=0).fillna(0)\n",
    "\n",
    "\n",
    "end_total_predict_time = time.time()\n",
    "print(f\"\\nОбщее время прогнозирования AutoARIMA: {end_total_predict_time - start_total_predict_time:.2f} сек.\")\n",
    "print(f\"Размер датафрейма прогнозов: {autoarima_forecast_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffbce7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Сводная таблица метрик AutoARIMA ---\n",
      "            Week      Month    Quarter\n",
      "MAE     4.621129   4.911177   7.141438\n",
      "RMSE    5.297589   5.838641   9.063509\n",
      "sMAPE  79.628187  81.025704  85.591646\n",
      "R2     -0.021185   0.035009  -0.072786\n",
      "\n",
      "--- Метрики AutoARIMA по товарам (Квартал) ---\n",
      "                   MAE       RMSE       sMAPE        R2\n",
      "item_id                                                \n",
      "STORE_1_064   0.308411   0.530896  192.389462 -0.015112\n",
      "STORE_1_065   0.741646   1.263027  169.073342 -0.050863\n",
      "STORE_1_090  49.851881  62.232142   97.052127 -0.856060\n",
      "STORE_1_252   6.463357   7.920427   42.856258 -0.062942\n",
      "STORE_1_325   3.562628   4.501222   75.023497 -0.013019\n",
      "STORE_1_339   2.234007   2.930407   79.991313 -0.177256\n",
      "STORE_1_376   0.768906   1.060925  175.856138 -0.008970\n",
      "STORE_1_546   1.698646   2.030667   62.306527 -0.007244\n",
      "STORE_1_547  10.529573  13.789116   99.457974 -0.300171\n",
      "STORE_1_555   6.451262   7.925201   28.910318  0.059428\n",
      "STORE_1_584   1.423710   2.252330  107.823722 -0.000371\n",
      "STORE_1_586   8.878835  11.249052   28.627503  0.020082\n",
      "STORE_1_587   6.720309   8.529202   23.119407  0.083525\n",
      "STORE_1_714   4.804403   6.226098   25.322471  0.241832\n",
      "STORE_1_727   2.683999   3.511919   76.064637 -0.004645\n"
     ]
    }
   ],
   "source": [
    "# --- Оценка AutoARIMA модели ---\n",
    "test_merged_autoarima = pd.merge(test_df[['date', 'item_id', 'cnt']],\n",
    "                                   autoarima_forecast_df,\n",
    "                                   on=['date', 'item_id'],\n",
    "                                   how='left')\n",
    "\n",
    "# --- Сводная таблица метрик AutoARIMA ---\n",
    "autoarima_results_summary = {}\n",
    "min_test_date = test_merged_autoarima['date'].min()\n",
    "\n",
    "# Горизонты для оценки\n",
    "horizons = {'Week': FH_WEEK, 'Month': FH_MONTH, 'Quarter': FH_QUARTER}\n",
    "\n",
    "# Рассчитываем метрики для каждого горизонта\n",
    "for name, days in horizons.items():\n",
    "    test_horizon = test_merged_autoarima[test_merged_autoarima['date'] <= min_test_date + pd.Timedelta(days=days-1)]\n",
    "    horizon_metrics_df = test_horizon.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_autoarima'])))\n",
    "    autoarima_results_summary[name] = horizon_metrics_df.mean()\n",
    "\n",
    "# Создаем и выводим итоговую таблицу\n",
    "autoarima_summary_df = pd.DataFrame(autoarima_results_summary)\n",
    "\n",
    "print(\"\\n--- Сводная таблица метрик AutoARIMA ---\")\n",
    "print(autoarima_summary_df)\n",
    "\n",
    "# Дополнительно: Вывод метрик по товарам для самого длинного горизонта (квартал)\n",
    "print(\"\\n--- Метрики AutoARIMA по товарам (Квартал) ---\")\n",
    "autoarima_metrics_quarter_df = test_merged_autoarima.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_autoarima'])))\n",
    "print(autoarima_metrics_quarter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f097c",
   "metadata": {},
   "source": [
    "### Обучение и прогнозы ETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec745361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Обучение ETS моделей ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bd329187fe435cbdb7bd85420914ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Обучение ETS:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Общее время обучения ETS: 3.56 сек.\n",
      "Успешно обучено моделей ETS: 15 из 15\n"
     ]
    }
   ],
   "source": [
    "# --- Обучение ETS ---\n",
    "\n",
    "ets_models = {}\n",
    "ets_fit_times = {}\n",
    "\n",
    "print(\"--- Обучение ETS ---\")\n",
    "start_total_time = time.time()\n",
    "\n",
    "# Оборачиваем цикл в tqdm\n",
    "for item_id in tqdm(train_df['item_id'].unique(), desc=\"Обучение ETS\"):\n",
    "    item_train_series = train_df[train_df['item_id'] == item_id].set_index('date')['cnt']\n",
    "\n",
    "    start_item_time = time.time()\n",
    "    try:\n",
    "        ets_model = ExponentialSmoothing(item_train_series,\n",
    "                                         trend='add',\n",
    "                                         seasonal='add',\n",
    "                                         seasonal_periods=7,\n",
    "                                         damped_trend=True,\n",
    "                                         initialization_method='estimated'\n",
    "                                         ).fit()\n",
    "        ets_models[item_id] = ets_model\n",
    "        end_item_time = time.time()\n",
    "        ets_fit_times[item_id] = end_item_time - start_item_time\n",
    "\n",
    "    except Exception as e:\n",
    "        # В случае ошибки можно добавить логирование или тихий пропуск\n",
    "        # print(f\"  Ошибка обучения ETS для {item_id}: {e}\") # Убрали вывод ошибки для чистоты tqdm\n",
    "        ets_models[item_id] = None\n",
    "        ets_fit_times[item_id] = None\n",
    "\n",
    "end_total_time = time.time()\n",
    "print(f\"\\nОбщее время обучения ETS: {end_total_time - start_total_time:.2f} сек.\")\n",
    "\n",
    "successful_fits = sum(1 for model in ets_models.values() if model is not None)\n",
    "print(f\"Успешно обучено моделей ETS: {successful_fits} из {len(train_df['item_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce6ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Генерация прогнозов ETS (на 90 дней) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b2c96bdd844b96b942ed3f5216964b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Прогнозирование ETS:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Общее время прогнозирования ETS: 0.20 сек.\n",
      "Размер датафрейма прогнозов: (1350, 3)\n",
      "\n",
      "--- Сводная таблица метрик ETS ---\n",
      "            Week      Month    Quarter\n",
      "MAE     4.148505   4.785016   7.283846\n",
      "RMSE    4.871507   5.832586   9.309611\n",
      "sMAPE  76.182163  79.566157  86.066540\n",
      "R2      0.097530   0.076141  -0.120005\n",
      "\n",
      "--- Метрики ETS по товарам (Квартал) ---\n",
      "                   MAE       RMSE       sMAPE        R2\n",
      "item_id                                                \n",
      "STORE_1_064   0.299807   0.527906  189.961938 -0.003711\n",
      "STORE_1_065   0.744034   1.267290  169.127595 -0.057970\n",
      "STORE_1_090  49.831912  62.808338   96.690206 -0.890589\n",
      "STORE_1_252   6.059311   7.578216   40.677824  0.026924\n",
      "STORE_1_325   3.439252   4.374867   73.419652  0.043056\n",
      "STORE_1_339   2.151949   2.845997   76.190753 -0.110412\n",
      "STORE_1_376   0.754685   1.047123  174.257140  0.017112\n",
      "STORE_1_546   1.558777   1.898724   61.523415  0.119395\n",
      "STORE_1_547  11.254831  14.858015  111.507831 -0.509556\n",
      "STORE_1_555   6.604460   8.057882   29.345797  0.027671\n",
      "STORE_1_584   1.397841   2.183679  106.973609  0.059683\n",
      "STORE_1_586   8.249483  10.954844   26.728356  0.070669\n",
      "STORE_1_587   6.536578   8.400328   22.555739  0.111011\n",
      "STORE_1_714   7.790550   9.345973   37.539755 -0.708373\n",
      "STORE_1_727   2.584216   3.494986   74.498494  0.005019\n"
     ]
    }
   ],
   "source": [
    "# --- Генерация прогнозов ETS ---\n",
    "\n",
    "ets_forecasts = []\n",
    "ets_predict_times = {}\n",
    "\n",
    "print(\"--- Генерация прогнозов ETS (на 90 дней) ---\")\n",
    "start_total_predict_time = time.time()\n",
    "\n",
    "# Определяем начало и конец периода прогнозирования\n",
    "start_pred_date = test_df['date'].min()\n",
    "end_pred_date = test_df['date'].max()\n",
    "# Создаем полный индекс дат для прогноза (на случай ошибок в predict)\n",
    "pred_dates_index = pd.date_range(start=start_pred_date, end=end_pred_date, freq='D')\n",
    "\n",
    "for item_id, model in tqdm(ets_models.items(), desc=\"Прогнозирование ETS\"):\n",
    "    item_forecast_df = pd.DataFrame({'date': pred_dates_index, 'item_id': item_id})\n",
    "    if model is not None:\n",
    "        start_item_predict_time = time.time()\n",
    "        try:\n",
    "            # Используем forecast вместо predict для ETSModel\n",
    "            item_preds = model.forecast(steps=FH_QUARTER) # Прогноз на FH_QUARTER шагов вперед\n",
    "            # Проверяем длину прогноза и индекс\n",
    "            if len(item_preds) == FH_QUARTER:\n",
    "                 item_preds.index = pred_dates_index # Присваиваем правильный индекс дат\n",
    "                 item_forecast_df['yhat_ets'] = item_preds.values\n",
    "            else:\n",
    "                 # Если длина не совпала, заполняем NaN\n",
    "                 print(f\"Warning: Прогноз для {item_id} имеет неверную длину ({len(item_preds)}), ожидалось {FH_QUARTER}. Заполняем NaN.\")\n",
    "                 item_forecast_df['yhat_ets'] = np.nan\n",
    "\n",
    "            end_item_predict_time = time.time()\n",
    "            ets_predict_times[item_id] = end_item_predict_time - start_item_predict_time\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка прогнозирования ETS для {item_id}: {e}. Заполняем NaN.\")\n",
    "            item_forecast_df['yhat_ets'] = np.nan\n",
    "            ets_predict_times[item_id] = None\n",
    "    else:\n",
    "         # Если модель не обучилась\n",
    "         item_forecast_df['yhat_ets'] = np.nan\n",
    "         ets_predict_times[item_id] = None\n",
    "\n",
    "    ets_forecasts.append(item_forecast_df)\n",
    "\n",
    "\n",
    "# Объединяем прогнозы\n",
    "ets_forecast_df = pd.concat(ets_forecasts).reset_index(drop=True)\n",
    "# Применяем clip(lower=0) и обрабатываем возможные NaN перед оценкой\n",
    "ets_forecast_df['yhat_ets'] = ets_forecast_df['yhat_ets'].clip(lower=0).fillna(0) # Заменяем NaN на 0 перед оценкой\n",
    "\n",
    "end_total_predict_time = time.time()\n",
    "print(f\"\\nОбщее время прогнозирования ETS: {end_total_predict_time - start_total_predict_time:.2f} сек.\")\n",
    "print(f\"Размер датафрейма прогнозов: {ets_forecast_df.shape}\")\n",
    "\n",
    "\n",
    "# --- Оценка ETS модели ---\n",
    "test_merged_ets = pd.merge(test_df[['date', 'item_id', 'cnt']],\n",
    "                           ets_forecast_df,\n",
    "                           on=['date', 'item_id'],\n",
    "                           how='left')\n",
    "\n",
    "# --- Сводная таблица метрик ETS ---\n",
    "ets_results_summary = {}\n",
    "min_test_date = test_merged_ets['date'].min()\n",
    "\n",
    "# Горизонты для оценки\n",
    "horizons = {'Week': FH_WEEK, 'Month': FH_MONTH, 'Quarter': FH_QUARTER}\n",
    "\n",
    "# Рассчитываем метрики для каждого горизонта\n",
    "for name, days in horizons.items():\n",
    "    # Фильтруем данные для текущего горизонта\n",
    "    test_horizon = test_merged_ets[test_merged_ets['date'] <= min_test_date + pd.Timedelta(days=days-1)]\n",
    "    # Считаем метрики по каждому товару и усредняем\n",
    "    horizon_metrics_df = test_horizon.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_ets'])))\n",
    "    # Сохраняем средние значения\n",
    "    ets_results_summary[name] = horizon_metrics_df.mean()\n",
    "\n",
    "# Создаем и выводим итоговую таблицу\n",
    "ets_summary_df = pd.DataFrame(ets_results_summary)\n",
    "\n",
    "print(\"\\n--- Сводная таблица метрик ETS ---\")\n",
    "print(ets_summary_df)\n",
    "\n",
    "# Дополнительно: Вывод метрик по товарам для самого длинного горизонта (квартал)\n",
    "print(\"\\n--- Метрики ETS по товарам (Квартал) ---\")\n",
    "ets_metrics_quarter_df = test_merged_ets.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_ets'])))\n",
    "print(ets_metrics_quarter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b63a1",
   "metadata": {},
   "source": [
    "### Обучение и прогнозы Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f1d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame с праздниками для Prophet ---\n",
      "          holiday         ds  lower_window  upper_window\n",
      "8       SuperBowl 2011-02-06            -1             1\n",
      "16  ValentinesDay 2011-02-14            -1             1\n",
      "23  PresidentsDay 2011-02-21            -1             1\n",
      "39      LentStart 2011-03-09            -1             1\n",
      "46      LentWeek2 2011-03-16            -1             1\n",
      "Всего уникальных праздников/событий: 30\n",
      "\n",
      "--- Обучение Prophet моделей (по одному на товар) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34f61c69ee2489ab82dd6b56cfc460a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Обучение Prophet:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:02:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:02:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:02:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Общее время обучения Prophet: 10.59 сек.\n",
      "Успешно обучено моделей Prophet: 15 из 15\n"
     ]
    }
   ],
   "source": [
    "# --- Подготовка данных для Prophet ---\n",
    "\n",
    "# Prophet требует столбцы 'ds' и 'y'\n",
    "train_prophet_df = train_df[['date', 'item_id', 'cnt']].rename(columns={'date': 'ds', 'cnt': 'y'})\n",
    "test_prophet_df = test_df[['date', 'item_id', 'cnt']].rename(columns={'date': 'ds', 'cnt': 'y'})\n",
    "\n",
    "# Подготовка датафрейма с праздниками\n",
    "# Возьмем информацию из исходного calendar_df\n",
    "# Нужны столбцы 'holiday' (название) и 'ds' (дата)\n",
    "original_calendar_df = pd.read_csv('data/shop_sales_dates.csv', parse_dates=['date'])\n",
    "holidays_df = original_calendar_df[['event_name_1', 'date']].copy()\n",
    "holidays_df.rename(columns={'event_name_1': 'holiday', 'date': 'ds'}, inplace=True)\n",
    "# Удаляем дни без событий и дубликаты (если один праздник на несколько дней)\n",
    "holidays_df = holidays_df.dropna(subset=['holiday'])\n",
    "holidays_df = holidays_df.drop_duplicates()\n",
    "\n",
    "# Добавим окна вокруг праздников (например, +/- 1 день)\n",
    "# Установим окно по умолчанию для всех праздников\n",
    "holidays_df['lower_window'] = -1\n",
    "holidays_df['upper_window'] = 1\n",
    "\n",
    "# Можно задать специфичные окна для важных праздников\n",
    "holidays_df.loc[holidays_df['holiday'] == 'Christmas', 'lower_window'] = -2\n",
    "holidays_df.loc[holidays_df['holiday'] == 'Christmas', 'upper_window'] = 0\n",
    "\n",
    "print(\"--- DataFrame с праздниками для Prophet ---\")\n",
    "print(holidays_df.head())\n",
    "print(f\"Всего уникальных праздников/событий: {holidays_df['holiday'].nunique()}\")\n",
    "\n",
    "\n",
    "# --- Обучение Prophet моделей ---\n",
    "prophet_models = {}\n",
    "prophet_fit_times = {}\n",
    "\n",
    "print(\"\\n--- Обучение Prophet моделей (по одному на товар) ---\")\n",
    "start_total_time = time.time()\n",
    "\n",
    "# Оборачиваем цикл в tqdm\n",
    "for item_id in tqdm(train_prophet_df['item_id'].unique(), desc=\"Обучение Prophet\"):\n",
    "    item_train_data = train_prophet_df[train_prophet_df['item_id'] == item_id][['ds', 'y']]\n",
    "    start_item_time = time.time()\n",
    "    try:\n",
    "        prophet_model = Prophet(holidays=holidays_df,\n",
    "                                weekly_seasonality=True,\n",
    "                                yearly_seasonality=True,\n",
    "                                daily_seasonality=False,\n",
    "                                seasonality_mode='additive',\n",
    "                                uncertainty_samples=0)\n",
    "\n",
    "        prophet_model.fit(item_train_data)\n",
    "        prophet_models[item_id] = prophet_model\n",
    "        end_item_time = time.time()\n",
    "        prophet_fit_times[item_id] = end_item_time - start_item_time\n",
    "    except Exception as e:\n",
    "\n",
    "        prophet_models[item_id] = None\n",
    "        prophet_fit_times[item_id] = None\n",
    "\n",
    "end_total_time = time.time()\n",
    "print(f\"\\nОбщее время обучения Prophet: {end_total_time - start_total_time:.2f} сек.\")\n",
    "\n",
    "successful_fits_prophet = sum(1 for model in prophet_models.values() if model is not None)\n",
    "print(f\"Успешно обучено моделей Prophet: {successful_fits_prophet} из {len(train_prophet_df['item_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf57050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Генерация прогнозов Prophet (на 90 дней) ---\n",
      "Создан датафрейм для прогнозирования Prophet: (1350, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca6e018f3f24388be8856d422606c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Прогнозирование Prophet:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Общее время прогнозирования Prophet: 1.44 сек.\n",
      "Размер датафрейма прогнозов: (1350, 3)\n",
      "\n",
      "--- Сводная таблица метрик Prophet ---\n",
      "            Week      Month    Quarter\n",
      "MAE     5.884783   5.265458   6.830777\n",
      "RMSE    6.649236   6.391558   8.720275\n",
      "sMAPE  86.743475  84.176485  86.461380\n",
      "R2     -1.069769  -0.301867  -0.202046\n",
      "\n",
      "--- Метрики Prophet по товарам (Квартал) ---\n",
      "                   MAE       RMSE       sMAPE        R2\n",
      "item_id                                                \n",
      "STORE_1_064   0.355948   0.532265  174.141063 -0.020356\n",
      "STORE_1_065   0.762910   1.237892  160.902594 -0.009455\n",
      "STORE_1_090  40.759729  54.469123   93.108385 -0.421881\n",
      "STORE_1_252   5.624783   6.711598   39.186467  0.236754\n",
      "STORE_1_325   3.487476   4.413237   67.288423  0.026197\n",
      "STORE_1_339   2.339674   3.038566   84.691213 -0.265764\n",
      "STORE_1_376   0.810543   1.209629  155.404069 -0.311636\n",
      "STORE_1_546   2.277895   2.754467  120.151307 -0.853244\n",
      "STORE_1_547  10.524452  12.973974   82.254119 -0.150995\n",
      "STORE_1_555   6.317727   7.753247   28.671895  0.099801\n",
      "STORE_1_584   1.547398   2.476071  107.266806 -0.208991\n",
      "STORE_1_586   6.028032   7.727333   19.636879  0.537601\n",
      "STORE_1_587  10.926744  12.561620   33.556925 -0.987902\n",
      "STORE_1_714   8.192071   9.681601   54.927031 -0.833277\n",
      "STORE_1_727   2.506281   3.263500   75.733528  0.132457\n"
     ]
    }
   ],
   "source": [
    "# --- Генерация прогнозов Prophet ---\n",
    "\n",
    "prophet_forecasts = []\n",
    "prophet_predict_times = {}\n",
    "\n",
    "print(\"--- Генерация прогнозов Prophet (на 90 дней) ---\")\n",
    "start_total_predict_time = time.time()\n",
    "\n",
    "# Создаем датафрейм с будущими датами для ВСЕХ товаров\n",
    "# Важно, чтобы он содержал все даты тестового периода для каждого item_id\n",
    "# Используем даты из test_df, чтобы гарантировать совпадение\n",
    "future_dates_all = test_df[['date', 'item_id']].drop_duplicates().reset_index(drop=True)\n",
    "# Переименовываем 'date' в 'ds' для Prophet\n",
    "future_dates_all.rename(columns={'date': 'ds'}, inplace=True)\n",
    "# Убедимся, что 'ds' имеет правильный тип\n",
    "future_dates_all['ds'] = pd.to_datetime(future_dates_all['ds'])\n",
    "\n",
    "print(f\"Создан датафрейм для прогнозирования Prophet: {future_dates_all.shape}\")\n",
    "\n",
    "\n",
    "for item_id, model in tqdm(prophet_models.items(), desc=\"Прогнозирование Prophet\"):\n",
    "    # Создаем заготовку с NaN на случай ошибки\n",
    "    item_future_dates = future_dates_all[future_dates_all['item_id'] == item_id][['ds']].copy()\n",
    "    item_forecast_df = item_future_dates.copy()\n",
    "    item_forecast_df['yhat'] = np.nan\n",
    "    item_forecast_df['item_id'] = item_id\n",
    "\n",
    "    if model is not None:\n",
    "        start_item_predict_time = time.time()\n",
    "        try:\n",
    "            # Генерируем прогноз\n",
    "            item_preds_df = model.predict(item_future_dates[['ds']])\n",
    "            # Выбираем нужные колонки и мерджим с заготовкой, чтобы сохранить все даты\n",
    "            item_preds_df = item_preds_df[['ds', 'yhat']]\n",
    "            # Обновляем yhat в заготовке\n",
    "            item_forecast_df = pd.merge(item_forecast_df[['ds', 'item_id']], item_preds_df, on='ds', how='left')\n",
    "\n",
    "            end_item_predict_time = time.time()\n",
    "            prophet_predict_times[item_id] = end_item_predict_time - start_item_predict_time\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка прогнозирования Prophet для {item_id}: {e}. Заполняем NaN.\")\n",
    "            # yhat уже NaN в заготовке\n",
    "            prophet_predict_times[item_id] = None\n",
    "    else:\n",
    "         # yhat уже NaN в заготовке\n",
    "         prophet_predict_times[item_id] = None\n",
    "\n",
    "    prophet_forecasts.append(item_forecast_df)\n",
    "\n",
    "\n",
    "# Объединяем прогнозы\n",
    "prophet_forecast_df = pd.concat(prophet_forecasts).reset_index(drop=True)\n",
    "# Переименуем 'yhat' и обработаем NaN/отрицательные значения\n",
    "prophet_forecast_df.rename(columns={'yhat': 'yhat_prophet'}, inplace=True)\n",
    "prophet_forecast_df['yhat_prophet'] = prophet_forecast_df['yhat_prophet'].clip(lower=0).fillna(0) # Заменяем NaN на 0\n",
    "# Переименуем 'ds' обратно в 'date' для слияния\n",
    "prophet_forecast_df.rename(columns={'ds': 'date'}, inplace=True)\n",
    "\n",
    "\n",
    "end_total_predict_time = time.time()\n",
    "print(f\"\\nОбщее время прогнозирования Prophet: {end_total_predict_time - start_total_predict_time:.2f} сек.\")\n",
    "print(f\"Размер датафрейма прогнозов: {prophet_forecast_df.shape}\")\n",
    "\n",
    "\n",
    "# --- Оценка Prophet модели ---\n",
    "test_merged_prophet = pd.merge(test_df[['date', 'item_id', 'cnt']],\n",
    "                               prophet_forecast_df,\n",
    "                               on=['date', 'item_id'],\n",
    "                               how='left')\n",
    "\n",
    "# --- Сводная таблица метрик Prophet ---\n",
    "prophet_results_summary = {}\n",
    "min_test_date = test_merged_prophet['date'].min()\n",
    "\n",
    "# Горизонты для оценки\n",
    "horizons = {'Week': FH_WEEK, 'Month': FH_MONTH, 'Quarter': FH_QUARTER}\n",
    "\n",
    "# Рассчитываем метрики для каждого горизонта\n",
    "for name, days in horizons.items():\n",
    "    # Фильтруем данные для текущего горизонта\n",
    "    test_horizon = test_merged_prophet[test_merged_prophet['date'] <= min_test_date + pd.Timedelta(days=days-1)]\n",
    "    # Считаем метрики по каждому товару и усредняем\n",
    "    horizon_metrics_df = test_horizon.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_prophet'])))\n",
    "    # Сохраняем средние значения\n",
    "    prophet_results_summary[name] = horizon_metrics_df.mean()\n",
    "\n",
    "# Создаем и выводим итоговую таблицу\n",
    "prophet_summary_df = pd.DataFrame(prophet_results_summary)\n",
    "\n",
    "print(\"\\n--- Сводная таблица метрик Prophet ---\")\n",
    "print(prophet_summary_df)\n",
    "\n",
    "# Дополнительно: Вывод метрик по товарам для самого длинного горизонта (квартал)\n",
    "print(\"\\n--- Метрики Prophet по товарам (Квартал) ---\")\n",
    "prophet_metrics_quarter_df = test_merged_prophet.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_prophet'])))\n",
    "print(prophet_metrics_quarter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85d05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модели ETS сохранены в: models/ets_models_STORE_1.joblib\n",
      "Модели Prophet сохранены в: models/prophet_models_STORE_1.joblib\n"
     ]
    }
   ],
   "source": [
    "# --- Сохранение моделей ---\n",
    "MODEL_DIR = \"models\" # Папка для сохранения моделей\n",
    "os.makedirs(MODEL_DIR, exist_ok=True) # Создаем папку, если ее нет\n",
    "\n",
    "# Сохранение ETS моделей\n",
    "ets_model_path = os.path.join(MODEL_DIR, f\"ets_models_{STORE_ID}.joblib\")\n",
    "try:\n",
    "    joblib.dump(ets_models, ets_model_path)\n",
    "    print(f\"Модели ETS сохранены в: {ets_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка сохранения моделей ETS: {e}\")\n",
    "\n",
    "# Сохранение Prophet моделей\n",
    "prophet_model_path = os.path.join(MODEL_DIR, f\"prophet_models_{STORE_ID}.joblib\")\n",
    "try:\n",
    "    # Очистим ненужные компоненты перед сохранением, чтобы уменьшить размер\n",
    "    for item_id, model in prophet_models.items():\n",
    "        if model is not None:\n",
    "            # Удаляем объект stan_fit, он занимает много места и не нужен для predict\n",
    "            if hasattr(model, 'stan_backend'): # Для новых версий Prophet\n",
    "               if hasattr(model.stan_backend, 'stan_fit'):\n",
    "                  del model.stan_backend.stan_fit\n",
    "            elif hasattr(model, 'stan_fit'): # Для старых версий Prophet\n",
    "                del model.stan_fit\n",
    "    joblib.dump(prophet_models, prophet_model_path)\n",
    "    print(f\"Модели Prophet сохранены в: {prophet_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка сохранения моделей Prophet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2948c7c8",
   "metadata": {},
   "source": [
    "## Обучение регрессионных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d647e42",
   "metadata": {},
   "source": [
    "### Обучение и прогнозы TBATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e893cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Обучение TBATS (sp=[7, 30.5, 365.25]) для 15 товаров ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab546e863cac444a8195b1bc7cd182e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Обучение TBATS:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение TBATS завершено.\n",
      "Общее время обучения: 1286.49 сек.\n",
      "Успешно обучено моделей: 15 из 15\n",
      "Среднее время обучения на 1 модель: 85.76 сек.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/edavletshin/courses/!time_series/exam/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Обучение TBATS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Словарь для хранения обученных моделей и времени обучения\n",
    "tbats_models = {}\n",
    "tbats_fit_times = {}\n",
    "\n",
    "# Определяем сезонные периоды (недельный, месячный)\n",
    "# Годовой (365.25) может требовать больше данных и времени\n",
    "SEASONAL_PERIODS = [7, 30.5, 365.25]\n",
    "\n",
    "print(f\"--- Обучение TBATS (sp={SEASONAL_PERIODS}) для {len(train_df['item_id'].unique())} товаров ---\")\n",
    "start_total_fit_time = time.time()\n",
    "\n",
    "for item_id in tqdm(train_df['item_id'].unique(), desc=\"Обучение TBATS\"):\n",
    "    start_item_fit_time = time.time()\n",
    "    # Готовим данные для sktime\n",
    "    item_train_series = train_df[train_df['item_id'] == item_id].set_index('date')['cnt'].sort_index()\n",
    "\n",
    "    # Проверка на достаточность данных (минимум 2 * max(sp))\n",
    "    min_len = int(2 * max(SEASONAL_PERIODS))\n",
    "    if len(item_train_series) < min_len:\n",
    "        print(f\"Пропуск {item_id}: недостаточно данных ({len(item_train_series)} точек, нужно >= {min_len})\")\n",
    "        tbats_models[item_id] = None\n",
    "        tbats_fit_times[item_id] = None\n",
    "        continue\n",
    "\n",
    "    # Инициализируем модель TBATS\n",
    "    # use_arma_errors=False может ускорить обучение, но потенциально снизить точность\n",
    "\n",
    "    forecaster = TBATS(\n",
    "        sp=SEASONAL_PERIODS,\n",
    "        use_box_cox=True,       # Попробуем с Box-Cox\n",
    "        use_trend=True,         # Позволим моделировать тренд\n",
    "        use_damped_trend=True,  # Позволим затухающий тренд\n",
    "        use_arma_errors=False,   # Установим в False для ускорения\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        forecaster.fit(y=item_train_series)\n",
    "        tbats_models[item_id] = forecaster\n",
    "        end_item_fit_time = time.time()\n",
    "        tbats_fit_times[item_id] = end_item_fit_time - start_item_fit_time\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка обучения TBATS для {item_id}: {e}\")\n",
    "        tbats_models[item_id] = None\n",
    "        tbats_fit_times[item_id] = None\n",
    "\n",
    "end_total_fit_time = time.time()\n",
    "successful_fits = sum(1 for model in tbats_models.values() if model is not None)\n",
    "print(f\"\\nОбучение TBATS завершено.\")\n",
    "print(f\"Общее время обучения: {end_total_fit_time - start_total_fit_time:.2f} сек.\")\n",
    "print(f\"Успешно обучено моделей: {successful_fits} из {len(train_df['item_id'].unique())}\")\n",
    "\n",
    "valid_fit_times = [t for t in tbats_fit_times.values() if t is not None]\n",
    "if valid_fit_times:\n",
    "    print(f\"Среднее время обучения на 1 модель: {np.mean(valid_fit_times):.2f} сек.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dccc929f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Генерация прогнозов TBATS (на 90 дней) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c6c528ba704afcb19820cdcc05967f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Прогнозирование TBATS:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Общее время прогнозирования TBATS: 0.28 сек.\n",
      "Размер датафрейма прогнозов: (1350, 3)\n",
      "\n",
      "--- Сводная таблица метрик TBATS ---\n",
      "            Week      Month    Quarter\n",
      "MAE     4.329738   4.608319   7.241769\n",
      "RMSE    4.994390   5.734522   8.990226\n",
      "sMAPE  77.679911  76.456057  84.910888\n",
      "R2      0.063350   0.012108  -0.369066\n",
      "\n",
      "--- Метрики TBATS по товарам (Квартал) ---\n",
      "                   MAE       RMSE       sMAPE        R2\n",
      "item_id                                                \n",
      "STORE_1_064   0.338971   0.526847  190.278028  0.000310\n",
      "STORE_1_065   0.743941   1.261755  168.115741 -0.048748\n",
      "STORE_1_090  35.960483  44.974450  104.449381  0.030620\n",
      "STORE_1_252   6.286513   7.771190   41.905530 -0.023264\n",
      "STORE_1_325   4.301255   5.333301  102.258372 -0.422161\n",
      "STORE_1_339   2.591551   3.134750   75.478387 -0.347165\n",
      "STORE_1_376   0.520605   1.119541  103.222161 -0.123541\n",
      "STORE_1_546   1.987388   2.389154   66.670490 -0.394267\n",
      "STORE_1_547  14.199131  16.840551   88.396328 -0.939279\n",
      "STORE_1_555   6.843135   8.496747   30.268658 -0.081127\n",
      "STORE_1_584   2.417868   2.981191  118.961730 -0.752574\n",
      "STORE_1_586  12.585505  15.280579   36.496623 -0.808163\n",
      "STORE_1_587   8.755160  10.755203   31.706643 -0.457273\n",
      "STORE_1_714   8.352067  10.371187   39.045686 -1.103733\n",
      "STORE_1_727   2.742966   3.616942   76.409560 -0.065632\n"
     ]
    }
   ],
   "source": [
    "# Шаг 5.4: Прогнозирование и Оценка TBATS\n",
    "\n",
    "# Список для хранения прогнозов\n",
    "tbats_forecasts = []\n",
    "tbats_predict_times = {}\n",
    "\n",
    "print(\"\\n--- Генерация прогнозов TBATS (на 90 дней) ---\")\n",
    "start_total_predict_time = time.time()\n",
    "\n",
    "# Определяем горизонт прогнозирования для sktime\n",
    "fh = ForecastingHorizon(np.arange(1, FH_QUARTER + 1), is_relative=True)\n",
    "\n",
    "# Даты тестового периода\n",
    "test_start_date = test_df['date'].min()\n",
    "test_end_date = test_df['date'].max()\n",
    "pred_dates_index = pd.date_range(start=test_start_date, end=test_end_date, freq='D')\n",
    "\n",
    "\n",
    "for item_id, model in tqdm(tbats_models.items(), desc=\"Прогнозирование TBATS\"):\n",
    "    # Заготовка DataFrame для товара\n",
    "    item_forecast_df = pd.DataFrame({'date': pred_dates_index, 'item_id': item_id})\n",
    "\n",
    "    if model is not None:\n",
    "        start_item_predict_time = time.time()\n",
    "        try:\n",
    "            # Генерируем прогноз\n",
    "            y_pred = model.predict(fh=fh)\n",
    "            # Присваиваем правильные даты\n",
    "            y_pred.index = pred_dates_index\n",
    "            item_forecast_df['yhat_tbats'] = y_pred.values\n",
    "\n",
    "            end_item_predict_time = time.time()\n",
    "            tbats_predict_times[item_id] = end_item_predict_time - start_item_predict_time\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка прогнозирования TBATS для {item_id}: {e}\")\n",
    "            item_forecast_df['yhat_tbats'] = np.nan # Заполняем NaN при ошибке\n",
    "            tbats_predict_times[item_id] = None\n",
    "    else:\n",
    "        item_forecast_df['yhat_tbats'] = np.nan # Заполняем NaN, если модель не обучилась\n",
    "        tbats_predict_times[item_id] = None\n",
    "\n",
    "    tbats_forecasts.append(item_forecast_df)\n",
    "\n",
    "# Объединяем прогнозы\n",
    "tbats_forecast_df = pd.concat(tbats_forecasts).reset_index(drop=True)\n",
    "# Обрабатываем NaN и отрицательные значения\n",
    "tbats_forecast_df['yhat_tbats'] = tbats_forecast_df['yhat_tbats'].clip(lower=0).fillna(0)\n",
    "\n",
    "\n",
    "end_total_predict_time = time.time()\n",
    "print(f\"\\nОбщее время прогнозирования TBATS: {end_total_predict_time - start_total_predict_time:.2f} сек.\")\n",
    "print(f\"Размер датафрейма прогнозов: {tbats_forecast_df.shape}\")\n",
    "\n",
    "\n",
    "# --- Оценка TBATS модели ---\n",
    "test_merged_tbats = pd.merge(test_df[['date', 'item_id', 'cnt']],\n",
    "                               tbats_forecast_df,\n",
    "                               on=['date', 'item_id'],\n",
    "                               how='left')\n",
    "\n",
    "# --- Сводная таблица метрик TBATS ---\n",
    "tbats_results_summary = {}\n",
    "min_test_date = test_merged_tbats['date'].min()\n",
    "\n",
    "# Горизонты для оценки\n",
    "horizons = {'Week': FH_WEEK, 'Month': FH_MONTH, 'Quarter': FH_QUARTER}\n",
    "\n",
    "# Рассчитываем метрики для каждого горизонта\n",
    "for name, days in horizons.items():\n",
    "    test_horizon = test_merged_tbats[test_merged_tbats['date'] <= min_test_date + pd.Timedelta(days=days-1)]\n",
    "    horizon_metrics_df = test_horizon.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_tbats'])))\n",
    "    tbats_results_summary[name] = horizon_metrics_df.mean()\n",
    "\n",
    "# Создаем и выводим итоговую таблицу\n",
    "tbats_summary_df = pd.DataFrame(tbats_results_summary)\n",
    "\n",
    "print(\"\\n--- Сводная таблица метрик TBATS ---\")\n",
    "print(tbats_summary_df)\n",
    "\n",
    "# Дополнительно: Вывод метрик по товарам для самого длинного горизонта (квартал)\n",
    "print(\"\\n--- Метрики TBATS по товарам (Квартал) ---\")\n",
    "tbats_metrics_quarter_df = test_merged_tbats.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_tbats'])))\n",
    "print(tbats_metrics_quarter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e2418",
   "metadata": {},
   "source": [
    "### Обучение и прогнозы ORBIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842fc5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Регрессоры для Orbit: ['sell_price', 'cashback', 'event_ColumbusDay', 'event_Eid al-Fitr', 'event_EidAlAdha', 'event_IndependenceDay', 'event_LaborDay', \"event_Mother's day\", 'event_NBAFinalsEnd', 'event_OtherEvent', 'event_Ramadan starts', 'event_SuperBowl']\n",
      "\n",
      "Типы данных регрессоров в orbit_train_df перед обучением:\n",
      "sell_price               float64\n",
      "cashback                   int64\n",
      "event_ColumbusDay          int64\n",
      "event_Eid al-Fitr          int64\n",
      "event_EidAlAdha            int64\n",
      "event_IndependenceDay      int64\n",
      "event_LaborDay             int64\n",
      "event_Mother's day         int64\n",
      "event_NBAFinalsEnd         int64\n",
      "event_OtherEvent           int64\n",
      "event_Ramadan starts       int64\n",
      "event_SuperBowl            int64\n",
      "dtype: object\n",
      "\n",
      "--- Обучение Orbit DLT (seasonal_period=7) для 15 товаров ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc9112a4c264328916ddbbc8b06cb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Обучение Orbit DLT:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 23:12:14 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:17 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:18 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:19 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:19 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:19 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:20 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:20 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:20 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:21 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:21 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:21 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:22 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:22 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n",
      "2025-04-26 23:12:22 - orbit - INFO - Optimizing (CmdStanPy) with algorithm: LBFGS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение Orbit DLT завершено.\n",
      "Общее время обучения: 8.78 сек.\n",
      "Успешно обучено моделей: 15 из 15\n",
      "Среднее время обучения на 1 модель: 0.58 сек.\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных и Обучение Orbit (DLT)\n",
    "\n",
    "# --- Подготовка данных для Orbit ---\n",
    "orbit_train_df = train_df.copy()\n",
    "orbit_train_df.rename(columns={'date': 'date_col', 'cnt': 'response_col'}, inplace=True)\n",
    "\n",
    "# Создаем dummy для event_name_1\n",
    "event_counts = orbit_train_df['event_name_1'].value_counts()\n",
    "top_n_events = 10\n",
    "frequent_events = event_counts.head(top_n_events).index.tolist()\n",
    "if 'NoEvent' not in frequent_events:\n",
    "     frequent_events.append('NoEvent')\n",
    "orbit_train_df['event_name_processed'] = orbit_train_df['event_name_1'].apply(lambda x: x if x in frequent_events else 'OtherEvent')\n",
    "event_dummies = pd.get_dummies(orbit_train_df['event_name_processed'], prefix='event')\n",
    "event_dummies.drop(columns=['event_NoEvent'], inplace=True, errors='ignore')\n",
    "\n",
    "# --- ИСПРАВЛЕНИЕ: Преобразуем dummies в int ---\n",
    "for col in event_dummies.columns:\n",
    "    event_dummies[col] = event_dummies[col].astype(int)\n",
    "\n",
    "\n",
    "orbit_train_df = pd.concat([orbit_train_df, event_dummies], axis=1)\n",
    "\n",
    "regressor_cols = ['sell_price', 'cashback'] + event_dummies.columns.tolist()\n",
    "print(\"Регрессоры для Orbit:\", regressor_cols)\n",
    "# Добавим проверку типов данных перед обучением\n",
    "print(\"\\nТипы данных регрессоров в orbit_train_df перед обучением:\")\n",
    "print(orbit_train_df[regressor_cols].dtypes)\n",
    "\n",
    "\n",
    "response_col = 'response_col'\n",
    "date_col = 'date_col'\n",
    "panel_col = 'item_id'\n",
    "\n",
    "# --- Обучение Orbit ---\n",
    "orbit_models = {}\n",
    "orbit_fit_times = {}\n",
    "\n",
    "print(f\"\\n--- Обучение Orbit DLT (seasonal_period=7) для {orbit_train_df[panel_col].nunique()} товаров ---\")\n",
    "start_total_fit_time = time.time()\n",
    "\n",
    "unique_items_orbit = orbit_train_df[panel_col].unique()\n",
    "\n",
    "for item_id in tqdm(unique_items_orbit, desc=\"Обучение Orbit DLT\"):\n",
    "    start_item_fit_time = time.time()\n",
    "    item_train_data = orbit_train_df[orbit_train_df[panel_col] == item_id]\n",
    "\n",
    "    if len(item_train_data) < 14:\n",
    "        print(f\"Пропуск {item_id}: недостаточно данных ({len(item_train_data)} точек)\")\n",
    "        orbit_models[item_id] = None\n",
    "        orbit_fit_times[item_id] = None\n",
    "        continue\n",
    "\n",
    "    # Инициализируем DLT\n",
    "    dlt = DLT(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        regressor_col=regressor_cols,\n",
    "        seasonality=7,\n",
    "        seed=42,\n",
    "        num_warmup=500,\n",
    "        num_sample=500,\n",
    "        estimator='stan-map'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Передаем только необходимые колонки с правильными типами\n",
    "        dlt.fit(df=item_train_data[[date_col, response_col] + regressor_cols])\n",
    "        orbit_models[item_id] = dlt\n",
    "        end_item_fit_time = time.time()\n",
    "        orbit_fit_times[item_id] = end_item_fit_time - start_item_fit_time\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка обучения Orbit DLT для {item_id}: {e}\")\n",
    "        # Дополнительно выведем типы данных на момент ошибки\n",
    "        print(f\"Типы данных для {item_id} при ошибке:\")\n",
    "        print(item_train_data[[date_col, response_col] + regressor_cols].dtypes)\n",
    "        orbit_models[item_id] = None\n",
    "        orbit_fit_times[item_id] = None\n",
    "\n",
    "\n",
    "end_total_fit_time = time.time()\n",
    "successful_fits = sum(1 for model in orbit_models.values() if model is not None)\n",
    "print(f\"\\nОбучение Orbit DLT завершено.\")\n",
    "print(f\"Общее время обучения: {end_total_fit_time - start_total_fit_time:.2f} сек.\")\n",
    "print(f\"Успешно обучено моделей: {successful_fits} из {len(unique_items_orbit)}\")\n",
    "\n",
    "valid_fit_times = [t for t in orbit_fit_times.values() if t is not None]\n",
    "if valid_fit_times:\n",
    "    print(f\"Среднее время обучения на 1 модель: {np.mean(valid_fit_times):.2f} сек.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838f246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Генерация прогнозов Orbit DLT (на 90 дней) ---\n",
      "Future DF подготовлен. Пример:\n",
      "    date_col      item_id  sell_price  cashback  event_ColumbusDay  event_Eid al-Fitr  event_EidAlAdha  event_IndependenceDay  event_LaborDay  event_Mother's day  event_NBAFinalsEnd  event_OtherEvent  event_Ramadan starts  event_SuperBowl\n",
      "0 2015-10-24  STORE_1_064        2.68         0                  0                  0                0                      0               0                   0                   0                 0                     0                0\n",
      "1 2015-10-25  STORE_1_064        2.68         0                  0                  0                0                      0               0                   0                   0                 0                     0                0\n",
      "2 2015-10-26  STORE_1_064        2.68         0                  0                  0                0                      0               0                   0                   0                 0                     0                0\n",
      "3 2015-10-27  STORE_1_064        2.68         0                  0                  0                0                      0               0                   0                   0                 0                     0                0\n",
      "4 2015-10-28  STORE_1_064        2.68         0                  0                  0                0                      0               0                   0                   0                 0                     0                0\n",
      "\n",
      "Типы данных регрессоров в future_df_full:\n",
      "sell_price               float64\n",
      "cashback                   int64\n",
      "event_ColumbusDay          int64\n",
      "event_Eid al-Fitr          int64\n",
      "event_EidAlAdha            int64\n",
      "event_IndependenceDay      int64\n",
      "event_LaborDay             int64\n",
      "event_Mother's day         int64\n",
      "event_NBAFinalsEnd         int64\n",
      "event_OtherEvent           int64\n",
      "event_Ramadan starts       int64\n",
      "event_SuperBowl            int64\n",
      "dtype: object\n",
      "\n",
      "Проверка NaN в регрессорах Future DF:\n",
      "sell_price               0\n",
      "cashback                 0\n",
      "event_ColumbusDay        0\n",
      "event_Eid al-Fitr        0\n",
      "event_EidAlAdha          0\n",
      "event_IndependenceDay    0\n",
      "event_LaborDay           0\n",
      "event_Mother's day       0\n",
      "event_NBAFinalsEnd       0\n",
      "event_OtherEvent         0\n",
      "event_Ramadan starts     0\n",
      "event_SuperBowl          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5233/1531487694.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  calendar_full_df['event_name_1'].fillna('NoEvent', inplace=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43391378fe9d4c43b7eededa7030fab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Прогнозирование Orbit DLT:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Общее время прогнозирования Orbit DLT: 0.71 сек.\n",
      "Размер датафрейма прогнозов: (1350, 3)\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных для прогноза и Оценка Orbit (DLT)\n",
    "\n",
    "orbit_forecasts = []\n",
    "orbit_predict_times = {}\n",
    "\n",
    "print(\"\\n--- Генерация прогнозов Orbit DLT (на 90 дней) ---\")\n",
    "start_total_predict_time = time.time()\n",
    "\n",
    "# --- Создание future_df для прогнозирования ---\n",
    "test_start_date = test_df['date'].min()\n",
    "test_end_date = test_df['date'].max()\n",
    "pred_dates_index = pd.date_range(start=test_start_date, end=test_end_date, freq='D')\n",
    "\n",
    "future_df_list = []\n",
    "for item_id in unique_items_orbit: # Используем unique_items_orbit из ячейки 5.5\n",
    "    future_df_list.append(pd.DataFrame({\n",
    "        'date_col': pred_dates_index,\n",
    "        panel_col: item_id # panel_col = 'item_id'\n",
    "    }))\n",
    "future_df_full = pd.concat(future_df_list).reset_index(drop=True)\n",
    "\n",
    "# Добавляем будущие значения регрессоров\n",
    "# Цена\n",
    "last_prices = train_df.loc[train_df.groupby('item_id')['date'].idxmax()][['item_id', 'sell_price']]\n",
    "future_df_full = pd.merge(future_df_full, last_prices, on=panel_col, how='left')\n",
    "# Кэшбэк\n",
    "last_cashback = train_df.loc[train_df.groupby('item_id')['date'].idxmax()][['item_id', 'cashback']]\n",
    "future_df_full = pd.merge(future_df_full, last_cashback, on=panel_col, how='left')\n",
    "\n",
    "# Праздники/События (event dummies)\n",
    "\n",
    "calendar_full_df = pd.read_csv('data/shop_sales_dates.csv', parse_dates=['date'])\n",
    "calendar_full_df['event_name_1'].fillna('NoEvent', inplace=True)\n",
    "# Используем те же frequent_events, что и при обучении\n",
    "calendar_full_df['event_name_processed'] = calendar_full_df['event_name_1'].apply(lambda x: x if x in frequent_events else 'OtherEvent')\n",
    "event_dummies_future_cal = pd.get_dummies(calendar_full_df['event_name_processed'], prefix='event')\n",
    "event_dummies_future_cal.drop(columns=['event_NoEvent'], inplace=True, errors='ignore')\n",
    "# --- Преобразуем dummies в int ---\n",
    "for col in event_dummies_future_cal.columns:\n",
    "    event_dummies_future_cal[col] = event_dummies_future_cal[col].astype(int)\n",
    "\n",
    "calendar_subset_df = pd.concat([calendar_full_df[['date']], event_dummies_future_cal], axis=1)\n",
    "calendar_subset_df.rename(columns={'date': 'date_col'}, inplace=True)\n",
    "\n",
    "\n",
    "future_df_full = pd.merge(future_df_full, calendar_subset_df, on='date_col', how='left')\n",
    "# Убедимся, что ВСЕ dummy колонки существуют и заполняем NaN нулями, приводим к int\n",
    "for col in event_dummies.columns: # Используем колонки из event_dummies, созданных при обучении\n",
    "     if col not in future_df_full.columns:\n",
    "           future_df_full[col] = 0 # Добавляем недостающие колонки\n",
    "     future_df_full[col] = future_df_full[col].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "print(\"Future DF подготовлен. Пример:\")\n",
    "print(future_df_full.head())\n",
    "print(\"\\nТипы данных регрессоров в future_df_full:\")\n",
    "print(future_df_full[regressor_cols].dtypes) # Проверяем типы\n",
    "print(\"\\nПроверка NaN в регрессорах Future DF:\")\n",
    "print(future_df_full[regressor_cols].isnull().sum()) # Должны быть нули\n",
    "\n",
    "\n",
    "# --- Прогнозирование ---\n",
    "for item_id, model in tqdm(orbit_models.items(), desc=\"Прогнозирование Orbit DLT\"):\n",
    "    item_forecast_df = pd.DataFrame({'date': pred_dates_index, 'item_id': item_id})\n",
    "    if model is not None:\n",
    "        start_item_predict_time = time.time()\n",
    "        try:\n",
    "            item_future_df = future_df_full[future_df_full[panel_col] == item_id]\n",
    "            # Убедимся, что передаем нужные колонки\n",
    "            predicted_df = model.predict(df=item_future_df[[date_col] + regressor_cols], decompose=False)\n",
    "            predicted_df = predicted_df[['date_col', 'prediction']].rename(columns={'date_col': 'date', 'prediction': 'yhat_orbit'})\n",
    "            item_forecast_df = pd.merge(item_forecast_df[['date', 'item_id']], predicted_df, on='date', how='left')\n",
    "            end_item_predict_time = time.time()\n",
    "            orbit_predict_times[item_id] = end_item_predict_time - start_item_predict_time\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка прогнозирования Orbit DLT для {item_id}: {e}\")\n",
    "            item_forecast_df['yhat_orbit'] = np.nan\n",
    "            orbit_predict_times[item_id] = None\n",
    "    else:\n",
    "        item_forecast_df['yhat_orbit'] = np.nan\n",
    "        orbit_predict_times[item_id] = None\n",
    "    orbit_forecasts.append(item_forecast_df)\n",
    "\n",
    "orbit_forecast_df = pd.concat(orbit_forecasts).reset_index(drop=True)\n",
    "orbit_forecast_df['yhat_orbit'] = orbit_forecast_df['yhat_orbit'].clip(lower=0).fillna(0)\n",
    "end_total_predict_time = time.time()\n",
    "print(f\"\\nОбщее время прогнозирования Orbit DLT: {end_total_predict_time - start_total_predict_time:.2f} сек.\")\n",
    "print(f\"Размер датафрейма прогнозов: {orbit_forecast_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "735e4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Сводная таблица метрик Orbit DLT ---\n",
      "            Week      Month    Quarter\n",
      "MAE     4.063869   4.625516   6.897581\n",
      "RMSE    4.828499   5.754251   8.906294\n",
      "sMAPE  79.971416  84.785811  95.731245\n",
      "R2      0.121218  -0.023963  -0.322541\n",
      "\n",
      "--- Метрики Orbit DLT по товарам (Квартал) ---\n",
      "                   MAE       RMSE       sMAPE        R2\n",
      "item_id                                                \n",
      "STORE_1_064   0.240415   0.546027  168.704188 -0.073799\n",
      "STORE_1_065   0.676795   1.342668  189.000317 -0.187569\n",
      "STORE_1_090  41.019722  51.027605   95.948976 -0.247880\n",
      "STORE_1_252   5.111924   6.954684   35.793986  0.180465\n",
      "STORE_1_325   4.439004   5.612750  111.376188 -0.575099\n",
      "STORE_1_339   3.010312   3.895439  138.034179 -1.080310\n",
      "STORE_1_376   0.482540   1.138731   71.747603 -0.162389\n",
      "STORE_1_546   2.252941   2.729819  114.441779 -0.820224\n",
      "STORE_1_547  14.110060  18.588138  169.765857 -1.362650\n",
      "STORE_1_555   6.373809   7.820595   29.012360  0.084094\n",
      "STORE_1_584   1.453232   2.553474  132.224219 -0.285759\n",
      "STORE_1_586   7.755359  10.380276   25.533058  0.165597\n",
      "STORE_1_587   9.003489  11.019001   32.728257 -0.529636\n",
      "STORE_1_714   4.914180   6.136821   26.093941  0.263419\n",
      "STORE_1_727   2.619928   3.848384   95.563768 -0.206370\n"
     ]
    }
   ],
   "source": [
    "# --- Оценка Orbit DLT модели ---\n",
    "test_merged_orbit = pd.merge(test_df[['date', 'item_id', 'cnt']],\n",
    "                             orbit_forecast_df,\n",
    "                             on=['date', 'item_id'],\n",
    "                             how='left')\n",
    "\n",
    "# --- Сводная таблица метрик Orbit DLT ---\n",
    "orbit_results_summary = {}\n",
    "min_test_date = test_merged_orbit['date'].min()\n",
    "horizons = {'Week': FH_WEEK, 'Month': FH_MONTH, 'Quarter': FH_QUARTER}\n",
    "for name, days in horizons.items():\n",
    "    test_horizon = test_merged_orbit[test_merged_orbit['date'] <= min_test_date + pd.Timedelta(days=days-1)]\n",
    "    horizon_metrics_df = test_horizon.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_orbit'])))\n",
    "    orbit_results_summary[name] = horizon_metrics_df.mean()\n",
    "orbit_summary_df = pd.DataFrame(orbit_results_summary)\n",
    "print(\"\\n--- Сводная таблица метрик Orbit DLT ---\")\n",
    "print(orbit_summary_df)\n",
    "\n",
    "# Дополнительно: Метрики по товарам (Квартал)\n",
    "print(\"\\n--- Метрики Orbit DLT по товарам (Квартал) ---\")\n",
    "orbit_metrics_quarter_df = test_merged_orbit.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_orbit'])))\n",
    "print(orbit_metrics_quarter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b87ba8",
   "metadata": {},
   "source": [
    "### Промежуточные метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d93891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Сравнение моделей: Горизонт - Неделя ---\n",
      "       Baseline  AutoARIMA     ETS  Prophet   TBATS   Orbit\n",
      "MAE       5.181      4.621   4.149    5.885   4.330   4.064\n",
      "RMSE      6.515      5.298   4.872    6.649   4.994   4.828\n",
      "sMAPE    69.216     79.628  76.182   86.743  77.680  79.971\n",
      "R2       -0.820     -0.020   0.098   -1.070   0.063   0.113\n",
      "\n",
      "--- Сравнение моделей: Горизонт - Месяц ---\n",
      "       Baseline  AutoARIMA     ETS  Prophet   TBATS   Orbit\n",
      "MAE       5.696      4.911   4.785    5.265   4.608   4.626\n",
      "RMSE      7.372      5.839   5.833    6.392   5.735   5.754\n",
      "sMAPE    70.952     81.026  79.566   84.176  76.456  84.786\n",
      "R2       -0.687      0.035   0.076   -0.302   0.012  -0.024\n",
      "\n",
      "--- Сравнение моделей: Горизонт - Квартал ---\n",
      "       Baseline  AutoARIMA     ETS  Prophet   TBATS   Orbit\n",
      "MAE       7.934      7.141   7.284    6.831   7.242   6.898\n",
      "RMSE     10.240      9.064   9.310    8.720   8.990   8.906\n",
      "sMAPE    78.637     85.592  86.067   86.461  84.911  95.731\n",
      "R2       -0.658     -0.073  -0.120   -0.202  -0.369  -0.323\n"
     ]
    }
   ],
   "source": [
    "# --- Создание сводных таблиц сравнения ВСЕХ моделей по горизонтам ---\n",
    "\n",
    "# Список моделей и их сводных таблиц\n",
    "model_summaries = {\n",
    "    'Baseline': 'baseline_summary_df',\n",
    "    'AutoARIMA': 'autoarima_summary_df',\n",
    "    'ETS': 'ets_summary_df',\n",
    "    'Prophet': 'prophet_summary_df',\n",
    "    'TBATS': 'tbats_summary_df',\n",
    "    'Orbit': 'orbit_summary_df'\n",
    "}\n",
    "\n",
    "# Проверяем наличие всех необходимых DataFrame'ов\n",
    "missing_dfs = []\n",
    "for df_name in model_summaries.values():\n",
    "    if df_name not in locals(): # locals() содержит локальные переменные\n",
    "        missing_dfs.append(df_name)\n",
    "\n",
    "if missing_dfs:\n",
    "    print(f\"Ошибка: Не найдены следующие DataFrame'ы с результатами: {', '.join(missing_dfs)}\")\n",
    "    print(\"Пожалуйста, убедитесь, что код оценки для ВСЕХ моделей был выполнен.\")\n",
    "else:\n",
    "    # --- Таблица для Недельного горизонта (FH=7) ---\n",
    "    week_metrics_list = {}\n",
    "    for model_name, df_name in model_summaries.items():\n",
    "        df = locals()[df_name] # Получаем DataFrame по имени\n",
    "        if 'Week' in df.columns:\n",
    "             week_metrics_list[model_name] = df['Week']\n",
    "        else:\n",
    "             print(f\"Предупреждение: Колонка 'Week' не найдена в {df_name}\")\n",
    "\n",
    "    metrics_week_comparison = pd.concat(week_metrics_list, axis=1)\n",
    "    print(\"\\n--- Сравнение моделей: Горизонт - Неделя ---\")\n",
    "    print(metrics_week_comparison.round(3))\n",
    "\n",
    "\n",
    "    # --- Таблица для Месячного горизонта (FH=30) ---\n",
    "    month_metrics_list = {}\n",
    "    for model_name, df_name in model_summaries.items():\n",
    "        df = locals()[df_name]\n",
    "        if 'Month' in df.columns:\n",
    "            month_metrics_list[model_name] = df['Month']\n",
    "        else:\n",
    "            print(f\"Предупреждение: Колонка 'Month' не найдена в {df_name}\")\n",
    "\n",
    "    metrics_month_comparison = pd.concat(month_metrics_list, axis=1)\n",
    "    print(\"\\n--- Сравнение моделей: Горизонт - Месяц ---\")\n",
    "    print(metrics_month_comparison.round(3))\n",
    "\n",
    "\n",
    "    # --- Таблица для Квартального горизонта (FH=90) ---\n",
    "    quarter_metrics_list = {}\n",
    "    for model_name, df_name in model_summaries.items():\n",
    "        df = locals()[df_name]\n",
    "        if 'Quarter' in df.columns:\n",
    "            quarter_metrics_list[model_name] = df['Quarter']\n",
    "        else:\n",
    "             print(f\"Предупреждение: Колонка 'Quarter' не найдена в {df_name}\")\n",
    "\n",
    "    metrics_quarter_comparison = pd.concat(quarter_metrics_list, axis=1)\n",
    "    print(\"\\n--- Сравнение моделей: Горизонт - Квартал ---\")\n",
    "    print(metrics_quarter_comparison.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Сравнение моделей: Горизонт - Неделя (Отсортировано по MAE) ---\n",
      "        Orbit     ETS   TBATS  AutoARIMA  Baseline  Prophet\n",
      "MAE     4.064   4.149   4.330      4.621     5.181    5.885\n",
      "RMSE    4.828   4.872   4.994      5.298     6.515    6.649\n",
      "sMAPE  79.971  76.182  77.680     79.628    69.216   86.743\n",
      "R2      0.113   0.098   0.063     -0.020    -0.820   -1.070\n",
      "\n",
      "--- Сравнение моделей: Горизонт - Месяц (Отсортировано по MAE) ---\n",
      "        TBATS   Orbit     ETS  AutoARIMA  Prophet  Baseline\n",
      "MAE     4.608   4.626   4.785      4.911    5.265     5.696\n",
      "RMSE    5.735   5.754   5.833      5.839    6.392     7.372\n",
      "sMAPE  76.456  84.786  79.566     81.026   84.176    70.952\n",
      "R2      0.012  -0.024   0.076      0.035   -0.302    -0.687\n",
      "\n",
      "--- Сравнение моделей: Горизонт - Квартал (Отсортировано по MAE) ---\n",
      "       Prophet   Orbit  AutoARIMA   TBATS     ETS  Baseline\n",
      "MAE      6.831   6.898      7.141   7.242   7.284     7.934\n",
      "RMSE     8.720   8.906      9.064   8.990   9.310    10.240\n",
      "sMAPE   86.461  95.731     85.592  84.911  86.067    78.637\n",
      "R2      -0.202  -0.323     -0.073  -0.369  -0.120    -0.658\n"
     ]
    }
   ],
   "source": [
    "# --- Создание СОРТИРОВАННЫХ сводных таблиц сравнения моделей по горизонтам (по MAE) ---\n",
    "\n",
    "# Проверяем их наличие еще раз на всякий случай\n",
    "comparison_dfs_exist = True\n",
    "for df_name in ['metrics_week_comparison', 'metrics_month_comparison', 'metrics_quarter_comparison']:\n",
    "    if df_name not in locals():\n",
    "        print(f\"Ошибка: Не найден DataFrame {df_name}. Пожалуйста, выполните предыдущий шаг.\")\n",
    "        comparison_dfs_exist = False\n",
    "        break\n",
    "\n",
    "if comparison_dfs_exist:\n",
    "    # --- Сортированная таблица для Недельного горизонта (FH=7) ---\n",
    "    metrics_week_sorted = metrics_week_comparison.sort_values(by='MAE', axis=1) # Сортируем КОЛОНКИ по строке MAE\n",
    "\n",
    "    print(\"\\n--- Сравнение моделей: Горизонт - Неделя (Отсортировано по MAE) ---\")\n",
    "    print(metrics_week_sorted.round(3))\n",
    "\n",
    "\n",
    "    # --- Сортированная таблица для Месячного горизонта (FH=30) ---\n",
    "    metrics_month_sorted = metrics_month_comparison.sort_values(by='MAE', axis=1)\n",
    "\n",
    "    print(\"\\n--- Сравнение моделей: Горизонт - Месяц (Отсортировано по MAE) ---\")\n",
    "    print(metrics_month_sorted.round(3))\n",
    "\n",
    "\n",
    "    # --- Сортированная таблица для Квартального горизонта (FH=90) ---\n",
    "    metrics_quarter_sorted = metrics_quarter_comparison.sort_values(by='MAE', axis=1)\n",
    "\n",
    "    print(\"\\n--- Сравнение моделей: Горизонт - Квартал (Отсортировано по MAE) ---\")\n",
    "    print(metrics_quarter_sorted.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d5197",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ce095",
   "metadata": {},
   "source": [
    "### Создание признаков и первое обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d4889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание признаков для LGBM...\n",
      "Объединенный датафрейм для создания признаков: (27285, 13)\n",
      "Проверка столбцов в combined_df_for_features:\n",
      "Index(['item_id', 'date_id', 'cnt', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year', 'event_name_1', 'event_type_1', 'cashback', 'sell_price'], dtype='object')\n",
      "Удалено 1350 строк с NaN из train_features_df.\n",
      "Размер train_features_df после удаления NaN: (24585, 38)\n",
      "Размер test_features_df: (1350, 38)\n",
      "Количество NaN в test_features_df: 0\n",
      "\n",
      "Количество признаков: 36\n",
      "Примеры признаков: ['wday', 'month', 'year', 'cashback', 'sell_price'] ... ['event_type_Cultural', 'event_type_National', 'event_type_Religious', 'event_type_Sporting', 'item_id_encoded']\n",
      "Категориальные признаки: ['item_id_encoded', 'dayofweek', 'month', 'year', 'dayofmonth', 'weekofyear', 'dayofyear', 'event_name_ColumbusDay', 'event_name_Eid al-Fitr', 'event_name_EidAlAdha', 'event_name_IndependenceDay', 'event_name_LaborDay', \"event_name_Mother's day\", 'event_name_NBAFinalsEnd', 'event_name_OtherEvent', 'event_name_Ramadan starts', 'event_name_SuperBowl', 'event_type_Cultural', 'event_type_National', 'event_type_Religious', 'event_type_Sporting']\n"
     ]
    }
   ],
   "source": [
    "def create_features(df, target_col='cnt'):\n",
    "    \"\"\"Создает признаки для модели LightGBM из датафрейма.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Убедимся, что 'date' точно есть и имеет правильный тип\n",
    "    if 'date' not in df.columns:\n",
    "        raise KeyError(\"Столбец 'date' отсутствует в DataFrame, передаваемом в create_features.\")\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # 1. Календарные признаки\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofmonth'] = df['date'].dt.day\n",
    "    df['weekofyear'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "\n",
    "    # 2. Лаговые признаки продаж (cnt)\n",
    "    lags = [7, 14, 21, 28, 35, 90]\n",
    "    df = df.sort_values(by=['item_id', 'date'])\n",
    "    for lag in lags:\n",
    "        df[f'{target_col}_lag_{lag}'] = df.groupby('item_id')[target_col].shift(lag)\n",
    "\n",
    "    # 3. Скользящие оконные признаки продаж (cnt)\n",
    "    windows = [7, 14, 28]\n",
    "    # Сдвиг на 7 дней, чтобы использовать данные до начала текущей недели\n",
    "    base_shift = 7\n",
    "    for window in windows:\n",
    "        df[f'{target_col}_roll_mean_{window}'] = df.groupby('item_id')[target_col].shift(base_shift).rolling(window).mean()\n",
    "        df[f'{target_col}_roll_std_{window}'] = df.groupby('item_id')[target_col].shift(base_shift).rolling(window).std()\n",
    "\n",
    "    # 4. Праздники/События (dummy для event_name_1)\n",
    "    df['event_name_processed'] = df['event_name_1'].apply(lambda x: x if x in frequent_events else 'OtherEvent')\n",
    "    event_dummies = pd.get_dummies(df['event_name_processed'], prefix='event_name') # Изменил префикс для ясности\n",
    "    event_dummies.drop(columns=['event_name_NoEvent'], inplace=True, errors='ignore')\n",
    "    for col in event_dummies.columns:\n",
    "         event_dummies[col] = event_dummies[col].astype(int)\n",
    "    df = pd.concat([df, event_dummies], axis=1)\n",
    "\n",
    "    # 4.1. Кодирование event_type_1 (dummy)\n",
    "    event_type_dummies = pd.get_dummies(df['event_type_1'], prefix='event_type')\n",
    "    event_type_dummies.drop(columns=['event_type_NoType'], inplace=True, errors='ignore') # Удаляем базовую категорию\n",
    "    for col in event_type_dummies.columns:\n",
    "        event_type_dummies[col] = event_type_dummies[col].astype(int)\n",
    "    df = pd.concat([df, event_type_dummies], axis=1)\n",
    "\n",
    "    # 5. ID товара как категориальный признак\n",
    "    # Создаем и сохраняем encoder для возможности обратного преобразования\n",
    "    item_encoder = LabelEncoder()\n",
    "    df['item_id_encoded'] = item_encoder.fit_transform(df['item_id'])\n",
    "\n",
    "\n",
    "    # Удаляем ненужные колонки\n",
    "    cols_to_drop = ['date_id', 'wm_yr_wk', 'weekday', 'event_name_1', 'event_name_processed', 'item_id', 'event_type_1']\n",
    "    df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
    "    df.head()\n",
    "\n",
    "    return df, item_encoder # Возвращаем encoder вместе с df\n",
    "\n",
    "# --- Применяем функцию для создания признаков ---\n",
    "print(\"Создание признаков для LGBM...\")\n",
    "\n",
    "combined_df_for_features = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print(f\"Объединенный датафрейм для создания признаков: {combined_df_for_features.shape}\")\n",
    "print(\"Проверка столбцов в combined_df_for_features:\")\n",
    "print(combined_df_for_features.columns) # Убедимся, что 'date' на месте\n",
    "\n",
    "full_df_features, item_le = create_features(combined_df_for_features) # Теперь передаем объединенный df\n",
    "\n",
    "\n",
    "\n",
    "# --- Разделяем на Train/Test уже с признаками ---\n",
    "# Важно использовать ту же самую split_date, что и раньше\n",
    "train_features_df = full_df_features[full_df_features['date'] < split_date].copy()\n",
    "test_features_df = full_df_features[full_df_features['date'] >= split_date].copy()\n",
    "\n",
    "# Удаляем строки с NaN из ТРЕНИРОВОЧНОЙ выборки\n",
    "train_initial_rows = len(train_features_df)\n",
    "train_features_df.dropna(inplace=True)\n",
    "print(f\"Удалено {train_initial_rows - len(train_features_df)} строк с NaN из train_features_df.\")\n",
    "print(f\"Размер train_features_df после удаления NaN: {train_features_df.shape}\")\n",
    "print(f\"Размер test_features_df: {test_features_df.shape}\")\n",
    "\n",
    "# Проверим NaN в тестовой выборке (не должно быть, если лаги < TEST_SIZE)\n",
    "print(f\"Количество NaN в test_features_df: {test_features_df.isnull().sum().sum()}\")\n",
    "\n",
    "\n",
    "# --- Определяем признаки (X) и таргет (y) ---\n",
    "TARGET = 'cnt'\n",
    "FEATURES = [col for col in train_features_df.columns if col not in [TARGET, 'date']]\n",
    "# Категориальные признаки для LightGBM\n",
    "CATEGORICAL_FEATURES = ['item_id_encoded', 'dayofweek', 'month', 'year', 'dayofmonth', 'weekofyear', 'dayofyear']\n",
    "event_name_dummies = [col for col in FEATURES if col.startswith('event_name_')] # Dummies от event_name\n",
    "event_type_dummies = [col for col in FEATURES if col.startswith('event_type_')] # Dummies от event_type\n",
    "CATEGORICAL_FEATURES.extend(event_name_dummies)\n",
    "CATEGORICAL_FEATURES.extend(event_type_dummies)\n",
    "CATEGORICAL_FEATURES = [col for col in CATEGORICAL_FEATURES if col in FEATURES] # Перепроверка\n",
    "\n",
    "\n",
    "X_train = train_features_df[FEATURES]\n",
    "y_train = train_features_df[TARGET]\n",
    "X_test = test_features_df[FEATURES]\n",
    "y_test = test_features_df[TARGET]\n",
    "\n",
    "print(f\"\\nКоличество признаков: {len(FEATURES)}\")\n",
    "print(\"Примеры признаков:\", FEATURES[:5], \"...\", FEATURES[-5:])\n",
    "print(\"Категориальные признаки:\", CATEGORICAL_FEATURES)\n",
    "# Сохраняем item_le для использования в оценке\n",
    "# Можно сделать его глобальным или передать в функцию оценки\n",
    "global saved_item_encoder\n",
    "saved_item_encoder = item_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9dfc52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Обучение LightGBM ---\n",
      "Обучение модели LGBM...\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Обучение LightGBM завершено за 9.56 сек.\n",
      "Лучшая итерация: 114\n",
      "\n",
      "--- Генерация прогнозов LightGBM ---\n",
      "Прогнозирование LightGBM завершено за 0.01 сек.\n",
      "\n",
      "Расчет метрик для LightGBM...\n",
      "\n",
      "--- Сводная таблица метрик LightGBM ---\n",
      "            Week      Month    Quarter\n",
      "MAE     4.122629   4.300051   5.143933\n",
      "RMSE    5.157964   5.400141   7.137492\n",
      "sMAPE  81.990873  81.278413  84.822289\n",
      "R2     -0.059663   0.036919   0.050941\n",
      "\n",
      "--- Метрики LightGBM по товарам (Квартал) ---\n",
      "                   MAE       RMSE       sMAPE        R2\n",
      "item_id                                                \n",
      "STORE_1_064   0.237064   0.563642  185.406266 -0.144201\n",
      "STORE_1_065   0.785532   1.395536  172.288577 -0.282931\n",
      "STORE_1_090  24.293486  37.991931  100.645914  0.308256\n",
      "STORE_1_252   4.977374   6.427280   35.524721  0.300050\n",
      "STORE_1_325   3.748262   4.563193   78.440566 -0.041105\n",
      "STORE_1_339   1.973566   2.681195   72.239723  0.014465\n",
      "STORE_1_376   0.552402   1.090162  172.040647 -0.065346\n",
      "STORE_1_546   1.570877   1.947875   64.484844  0.073214\n",
      "STORE_1_547   9.341790  12.029438   89.615813  0.010494\n",
      "STORE_1_555   6.432932   7.739880   29.685255  0.102902\n",
      "STORE_1_584   1.465453   2.286434  118.876363 -0.030894\n",
      "STORE_1_586   7.444701   9.880933   25.137712  0.243944\n",
      "STORE_1_587   6.569327   8.470148   23.339725  0.096172\n",
      "STORE_1_714   5.278579   6.500879   27.855943  0.173433\n",
      "STORE_1_727   2.487650   3.493858   76.752259  0.005661\n",
      "\n",
      "--- Важность признаков LightGBM ---\n",
      "                       feature  importance\n",
      "8                    dayofyear         681\n",
      "7                   weekofyear         534\n",
      "6                   dayofmonth         306\n",
      "35             item_id_encoded         253\n",
      "19            cnt_roll_mean_28         222\n",
      "20             cnt_roll_std_28         177\n",
      "4                   sell_price         176\n",
      "15             cnt_roll_mean_7         175\n",
      "9                    cnt_lag_7         146\n",
      "0                         wday          90\n",
      "5                    dayofweek          89\n",
      "14                  cnt_lag_90          82\n",
      "18             cnt_roll_std_14          75\n",
      "17            cnt_roll_mean_14          68\n",
      "16              cnt_roll_std_7          65\n",
      "10                  cnt_lag_14          63\n",
      "12                  cnt_lag_28          54\n",
      "2                         year          49\n",
      "11                  cnt_lag_21          42\n",
      "13                  cnt_lag_35          41\n",
      "1                        month          16\n",
      "3                     cashback          12\n",
      "32         event_type_National           3\n",
      "33        event_type_Religious           1\n",
      "29   event_name_Ramadan_starts           0\n",
      "34         event_type_Sporting           0\n",
      "31         event_type_Cultural           0\n",
      "30        event_name_SuperBowl           0\n",
      "26     event_name_Mother's_day           0\n",
      "28       event_name_OtherEvent           0\n",
      "27     event_name_NBAFinalsEnd           0\n",
      "25         event_name_LaborDay           0\n",
      "24  event_name_IndependenceDay           0\n",
      "22      event_name_Eid_al-Fitr           0\n",
      "21      event_name_ColumbusDay           0\n",
      "23        event_name_EidAlAdha           0\n"
     ]
    }
   ],
   "source": [
    "# Шаг 6.2: Обучение, Прогнозирование и Оценка LightGBM\n",
    "\n",
    "print(\"\\n--- Обучение LightGBM ---\")\n",
    "start_fit_time = time.time()\n",
    "\n",
    "# Параметры LightGBM\n",
    "params = {\n",
    "    'objective': 'regression_l1', # MAE loss\n",
    "    'metric': 'mae',\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "    'boosting_type': 'gbdt',\n",
    "}\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(**params)\n",
    "\n",
    "# Обучение модели с early stopping на тестовом наборе\n",
    "# (Помним про потенциальную \"утечку\" информации при использовании теста для early stopping)\n",
    "print(\"Обучение модели LGBM...\")\n",
    "model_lgb.fit(X_train, y_train,\n",
    "              eval_set=[(X_test, y_test)],\n",
    "              eval_metric='mae',\n",
    "              callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)],\n",
    "              categorical_feature=CATEGORICAL_FEATURES) # Передаем категориальные признаки\n",
    "\n",
    "end_fit_time = time.time()\n",
    "print(f\"Обучение LightGBM завершено за {end_fit_time - start_fit_time:.2f} сек.\")\n",
    "if model_lgb.best_iteration_ is not None:\n",
    "    print(f\"Лучшая итерация: {model_lgb.best_iteration_}\")\n",
    "else:\n",
    "    print(\"Ранняя остановка не сработала (возможно, все n_estimators использованы).\")\n",
    "\n",
    "\n",
    "# --- Прогнозирование LightGBM ---\n",
    "print(\"\\n--- Генерация прогнозов LightGBM ---\")\n",
    "start_predict_time = time.time()\n",
    "\n",
    "# Используем лучшую итерацию, если она есть, иначе все деревья\n",
    "best_iter = model_lgb.best_iteration_ if model_lgb.best_iteration_ is not None else params['n_estimators']\n",
    "y_pred_lgb = model_lgb.predict(X_test, num_iteration=best_iter)\n",
    "# Обрезаем отрицательные значения\n",
    "y_pred_lgb = np.maximum(0, y_pred_lgb)\n",
    "\n",
    "end_predict_time = time.time()\n",
    "print(f\"Прогнозирование LightGBM завершено за {end_predict_time - start_predict_time:.2f} сек.\")\n",
    "\n",
    "\n",
    "# --- Оценка LightGBM модели ---\n",
    "# Используем сохраненный LabelEncoder для декодирования item_id\n",
    "try:\n",
    "    # Проверяем, доступен ли encoder, сохраненный в предыдущей ячейке\n",
    "    decoder_map = dict(zip(saved_item_encoder.transform(saved_item_encoder.classes_), saved_item_encoder.classes_))\n",
    "except NameError:\n",
    "    print(\"Ошибка: LabelEncoder для item_id (saved_item_encoder) не найден.\")\n",
    "    # Попытка восстановить, если train_df все еще доступен\n",
    "    try:\n",
    "        item_le_fallback = LabelEncoder().fit(train_df['item_id']) # train_df до создания признаков\n",
    "        decoder_map = dict(zip(item_le_fallback.transform(item_le_fallback.classes_), item_le_fallback.classes_))\n",
    "        print(\"Используется восстановленный LabelEncoder.\")\n",
    "    except NameError:\n",
    "        print(\"Не удалось восстановить LabelEncoder. Декодирование item_id невозможно.\")\n",
    "        decoder_map = {} # Оставляем пустым, оценка по товарам не будет работать корректно\n",
    "\n",
    "\n",
    "# Создаем DataFrame с результатами для оценки по горизонтам\n",
    "lgbm_results_df = pd.DataFrame({\n",
    "    'date': test_features_df['date'].values, # Используем .values для избежания проблем с индексом\n",
    "    'item_id': test_features_df['item_id_encoded'].map(decoder_map), # Декодируем item_id\n",
    "    'cnt': y_test.values,\n",
    "    'yhat_lgbm': y_pred_lgb\n",
    "})\n",
    "# Проверим, удалось ли декодирование\n",
    "if lgbm_results_df['item_id'].isnull().any():\n",
    "    print(\"Предупреждение: Не удалось декодировать некоторые item_id_encoded.\")\n",
    "\n",
    "\n",
    "# --- Сводная таблица метрик LightGBM ---\n",
    "lgbm_results_summary = {}\n",
    "min_test_date = lgbm_results_df['date'].min()\n",
    "\n",
    "horizons = {'Week': FH_WEEK, 'Month': FH_MONTH, 'Quarter': FH_QUARTER}\n",
    "print(\"\\nРасчет метрик для LightGBM...\")\n",
    "for name, days in horizons.items():\n",
    "    test_horizon = lgbm_results_df[lgbm_results_df['date'] <= min_test_date + pd.Timedelta(days=days-1)]\n",
    "    if test_horizon.empty or test_horizon['item_id'].isnull().all(): # Добавлена проверка на null в item_id\n",
    "        print(f\"Предупреждение: Нет данных или не удалось декодировать item_id для горизонта '{name}'.\")\n",
    "        lgbm_results_summary[name] = pd.Series({'MAE': np.nan, 'RMSE': np.nan, 'sMAPE': np.nan, 'R2': np.nan})\n",
    "        continue\n",
    "    # Считаем метрики по каждому товару и усредняем\n",
    "    # Добавим обработку ошибок на случай проблем с декодированием или пустыми группами\n",
    "    try:\n",
    "        horizon_metrics_df = test_horizon.groupby('item_id').filter(lambda x: not x.empty).groupby('item_id')\\\n",
    "                                     .apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_lgbm'])))\n",
    "        if not horizon_metrics_df.empty:\n",
    "             lgbm_results_summary[name] = horizon_metrics_df.mean()\n",
    "        else:\n",
    "             print(f\"Предупреждение: Нет валидных групп для расчета метрик горизонта '{name}'.\")\n",
    "             lgbm_results_summary[name] = pd.Series({'MAE': np.nan, 'RMSE': np.nan, 'sMAPE': np.nan, 'R2': np.nan})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при расчете метрик для горизонта '{name}': {e}\")\n",
    "        lgbm_results_summary[name] = pd.Series({'MAE': np.nan, 'RMSE': np.nan, 'sMAPE': np.nan, 'R2': np.nan})\n",
    "\n",
    "\n",
    "# Создаем и выводим итоговую таблицу\n",
    "lgbm_summary_df = pd.DataFrame(lgbm_results_summary)\n",
    "print(\"\\n--- Сводная таблица метрик LightGBM ---\")\n",
    "print(lgbm_summary_df)\n",
    "\n",
    "\n",
    "# Дополнительно: Метрики по товарам (Квартал)\n",
    "print(\"\\n--- Метрики LightGBM по товарам (Квартал) ---\")\n",
    "if not lgbm_results_df.empty and not lgbm_results_df['item_id'].isnull().all():\n",
    "    try:\n",
    "        lgbm_metrics_quarter_df = lgbm_results_df.groupby('item_id').filter(lambda x: not x.empty).groupby('item_id')\\\n",
    "                                             .apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_lgbm'])))\n",
    "        print(lgbm_metrics_quarter_df)\n",
    "    except Exception as e:\n",
    "         print(f\"Ошибка при расчете метрик по товарам: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame lgbm_results_df пуст или не содержит валидных item_id, метрики по товарам не рассчитаны.\")\n",
    "\n",
    "\n",
    "# Дополнительно: Важность признаков\n",
    "try:\n",
    "    print(\"\\n--- Важность признаков LightGBM ---\")\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': model_lgb.feature_name_,\n",
    "        'importance': model_lgb.feature_importances_\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "    print(feature_importance_df)\n",
    "except Exception as e:\n",
    "    print(f\"Не удалось получить важность признаков: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531c7e7",
   "metadata": {},
   "source": [
    "### Упрощенные признаки, повторное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d1014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание УПРОЩЕННЫХ признаков для LGBM (с хардкодом ID)...\n",
      "Объединенный датафрейм: (27285, 13)\n",
      "Удалено 1350 строк с NaN из train_features_df.\n",
      "Размер train_features_df: (24585, 23)\n",
      "Размер test_features_df: (1350, 23)\n",
      "Количество NaN в test_features_df: 0\n",
      "\n",
      "Количество признаков: 21\n",
      "Первые 5 признаков: ['wday', 'month', 'year', 'sell_price', 'dayofweek']\n",
      "Последние 5 признаков: ['cnt_roll_mean_14', 'cnt_roll_std_14', 'cnt_roll_mean_28', 'cnt_roll_std_28', 'item_id_encoded']\n",
      "Категориальные признаки: ['item_id_encoded', 'dayofweek', 'year', 'dayofmonth', 'weekofyear', 'dayofyear', 'wday']\n"
     ]
    }
   ],
   "source": [
    "def create_features_simplified(df, target_col='cnt'):\n",
    "    \"\"\"Создает УПРОЩЕННЫЙ набор признаков для модели LightGBM.\"\"\"\n",
    "    df = df.copy()\n",
    "    if 'date' not in df.columns: raise KeyError(\"Столбец 'date' отсутствует.\")\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # 1. ВАЖНЫЕ Календарные признаки\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofmonth'] = df['date'].dt.day\n",
    "    df['weekofyear'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    # wday остается, если был на входе\n",
    "\n",
    "    # 2. ВАЖНЫЕ Лаговые признаки продаж\n",
    "    lags = [7, 14, 21, 28, 35, 90]\n",
    "    df = df.sort_values(by=['item_id', 'date'])\n",
    "    for lag in lags:\n",
    "        df[f'{target_col}_lag_{lag}'] = df.groupby('item_id')[target_col].shift(lag)\n",
    "\n",
    "    # 3. ВАЖНЫЕ Скользящие оконные признаки\n",
    "    windows = [7, 14, 28]\n",
    "    base_shift = 7\n",
    "    for window in windows:\n",
    "        shifted = df.groupby('item_id')[target_col].shift(base_shift)\n",
    "        df[f'{target_col}_roll_mean_{window}'] = shifted.rolling(window, min_periods=1).mean()\n",
    "        df[f'{target_col}_roll_std_{window}'] = shifted.rolling(window, min_periods=2).std()\n",
    "\n",
    "\n",
    "    # --- 5. УПРОЩЕННОЕ Кодирование ID товара (Жесткий маппинг) ---\n",
    "    # Словарь: ключ - исходный ID, значение - код 0-14\n",
    "    item_id_map = {\n",
    "        'STORE_1_064': 0, 'STORE_1_065': 1, 'STORE_1_090': 2, 'STORE_1_252': 3,\n",
    "        'STORE_1_325': 4, 'STORE_1_339': 5, 'STORE_1_376': 6, 'STORE_1_546': 7,\n",
    "        'STORE_1_547': 8, 'STORE_1_555': 9, 'STORE_1_584': 10, 'STORE_1_586': 11,\n",
    "        'STORE_1_587': 12, 'STORE_1_714': 13, 'STORE_1_727': 14\n",
    "    }\n",
    "    # Применяем маппинг, неизвестные ID получат NaN (потом заменим на -1 или 0)\n",
    "    df['item_id_encoded'] = df['item_id'].map(item_id_map)\n",
    "    # Заполняем пропуски (если вдруг появятся не те ID) значением -1\n",
    "    df['item_id_encoded'] = df['item_id_encoded'].fillna(-1)\n",
    "    # Преобразуем в целочисленный тип\n",
    "    df['item_id_encoded'] = df['item_id_encoded'].astype('int16') # int16 достаточно для 0-14\n",
    "\n",
    "\n",
    "    # 7. Удаляем ненужные столбцы\n",
    "    cols_to_drop = [\n",
    "        'date_id', 'wm_yr_wk', 'weekday', # Ненужные календарные/id\n",
    "        'event_name_1', 'event_type_1',    # Ненужные события\n",
    "        'item_id',                         # Исходный ID товара\n",
    "        'cashback'                         # Ненужный кэшбэк (если был)\n",
    "    ]\n",
    "    # Проверяем наличие столбцов перед удалением\n",
    "    cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "    df.drop(columns=cols_to_drop_existing, inplace=True, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Применяем УПРОЩЕННУЮ функцию для создания признаков ---\n",
    "print(\"Создание УПРОЩЕННЫХ признаков для LGBM (с хардкодом ID)...\")\n",
    "\n",
    "# Объединяем train и test\n",
    "combined_df_for_features = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print(f\"Объединенный датафрейм: {combined_df_for_features.shape}\")\n",
    "\n",
    "\n",
    "full_df_features_simplified = create_features_simplified(combined_df_for_features)\n",
    "\n",
    "# --- Разделяем на Train/Test ---\n",
    "train_features_df = full_df_features_simplified[full_df_features_simplified['date'] < split_date].copy()\n",
    "test_features_df = full_df_features_simplified[full_df_features_simplified['date'] >= split_date].copy()\n",
    "\n",
    "# Удаляем строки с NaN из Train\n",
    "train_initial_rows = len(train_features_df); train_features_df.dropna(inplace=True)\n",
    "print(f\"Удалено {train_initial_rows - len(train_features_df)} строк с NaN из train_features_df.\")\n",
    "print(f\"Размер train_features_df: {train_features_df.shape}\")\n",
    "print(f\"Размер test_features_df: {test_features_df.shape}\")\n",
    "print(f\"Количество NaN в test_features_df: {test_features_df.isnull().sum().sum()}\")\n",
    "\n",
    "\n",
    "# --- Определяем признаки (X) и таргет (y) ---\n",
    "TARGET = 'cnt'\n",
    "FEATURES = [col for col in train_features_df.columns if col not in [TARGET, 'date']]\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'item_id_encoded',\n",
    "    'dayofweek', 'year', 'dayofmonth',\n",
    "    'weekofyear', 'dayofyear', 'wday'\n",
    "]\n",
    "CATEGORICAL_FEATURES = [col for col in CATEGORICAL_FEATURES if col in FEATURES]\n",
    "\n",
    "\n",
    "\n",
    "X_train = train_features_df[FEATURES]\n",
    "y_train = train_features_df[TARGET]\n",
    "X_test = test_features_df[FEATURES]\n",
    "y_test = test_features_df[TARGET]\n",
    "\n",
    "print(f\"\\nКоличество признаков: {len(FEATURES)}\")\n",
    "print(\"Первые 5 признаков:\", FEATURES[:5])\n",
    "print(\"Последние 5 признаков:\", FEATURES[-5:])\n",
    "print(\"Категориальные признаки:\", CATEGORICAL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Обучение LightGBM (упрощенные признаки) ---\n",
      "Обучение финальной модели LGBM...\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Обучение LightGBM завершено за 0.33 сек.\n",
      "\n",
      "Расчет метрик для LightGBM (упрощенные признаки)...\n",
      "\n",
      "--- Сводная таблица метрик LightGBM (упрощенные признаки) ---\n",
      "            Week      Month    Quarter\n",
      "MAE     4.365823   4.390217   5.284014\n",
      "RMSE    5.363034   5.526117   7.226407\n",
      "sMAPE  85.884854  82.574130  86.079746\n",
      "R2     -0.122750   0.016399   0.019858\n",
      "\n",
      "--- Важность признаков LightGBM (упрощенные признаки) ---\n",
      "             feature  importance\n",
      "7          dayofyear         401\n",
      "6         weekofyear         265\n",
      "5         dayofmonth         131\n",
      "20   item_id_encoded         124\n",
      "19   cnt_roll_std_28         104\n",
      "14   cnt_roll_mean_7         101\n",
      "3         sell_price          96\n",
      "18  cnt_roll_mean_28          81\n",
      "8          cnt_lag_7          71\n",
      "0               wday          53\n",
      "16  cnt_roll_mean_14          40\n",
      "11        cnt_lag_28          39\n",
      "15    cnt_roll_std_7          29\n",
      "13        cnt_lag_90          28\n",
      "9         cnt_lag_14          27\n",
      "4          dayofweek          24\n",
      "2               year          24\n",
      "10        cnt_lag_21          22\n",
      "1              month          18\n",
      "17   cnt_roll_std_14          17\n"
     ]
    }
   ],
   "source": [
    "# Обучение, Прогнозирование, Оценка - Упрощенная версия\n",
    "\n",
    "print(\"\\n--- Обучение LightGBM (упрощенные признаки) ---\")\n",
    "start_fit_time = time.time()\n",
    "\n",
    "# Параметры LightGBM\n",
    "params = {\n",
    "    'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 57,\n",
    "    'learning_rate': 0.1, 'num_leaves': 31, 'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.9, 'bagging_freq': 1, 'verbose': -1,\n",
    "    'n_jobs': -1, 'seed': 42, 'boosting_type': 'gbdt'\n",
    "    # Убрали n_estimators=2000 и early_stopping для финальной модели\n",
    "}\n",
    "\n",
    "# Обучаем финальную модель с фиксированными параметрами\n",
    "model_lgb_simplified = lgb.LGBMRegressor(**params)\n",
    "print(\"Обучение финальной модели LGBM...\")\n",
    "model_lgb_simplified.fit(X_train, y_train, categorical_feature=CATEGORICAL_FEATURES)\n",
    "\n",
    "\n",
    "end_fit_time = time.time()\n",
    "print(f\"Обучение LightGBM завершено за {end_fit_time - start_fit_time:.2f} сек.\")\n",
    "\n",
    "# --- Оценка LightGBM модели ---\n",
    "# --- Создаем обратный маппинг для item_id ---\n",
    "item_id_map_reverse = { # Обратный словарь к тому, что в create_features\n",
    "    0: 'STORE_1_064', 1: 'STORE_1_065', 2: 'STORE_1_090', 3: 'STORE_1_252',\n",
    "    4: 'STORE_1_325', 5: 'STORE_1_339', 6: 'STORE_1_376', 7: 'STORE_1_546',\n",
    "    8: 'STORE_1_547', 9: 'STORE_1_555', 10: 'STORE_1_584', 11: 'STORE_1_586',\n",
    "    12: 'STORE_1_587', 13: 'STORE_1_714', 14: 'STORE_1_727'\n",
    "}\n",
    "\n",
    "# Создаем DataFrame с результатами\n",
    "lgbm_results_df = pd.DataFrame({\n",
    "    'date': test_features_df['date'].values,\n",
    "    'item_id_encoded': test_features_df['item_id_encoded'].values, # Закодированный ID\n",
    "    'cnt': y_test.values,\n",
    "    'yhat_lgbm': y_pred_lgb # Или другой прогноз, если нужно\n",
    "})\n",
    "# Добавляем исходный item_id для группировки при оценке\n",
    "lgbm_results_df['item_id'] = lgbm_results_df['item_id_encoded'].map(item_id_map_reverse)\n",
    "\n",
    "\n",
    "# --- Сводная таблица метрик LightGBM ---\n",
    "lgbm_simplified_summary_df = pd.DataFrame() # Инициализируем на случай ошибок\n",
    "if 'item_id' in lgbm_results_df.columns and not lgbm_results_df['item_id'].isnull().all():\n",
    "    lgbm_results_summary = {}\n",
    "    min_test_date = lgbm_results_df['date'].min()\n",
    "    horizons = {'Week': 7, 'Month': 30, 'Quarter': 90}\n",
    "    print(\"\\nРасчет метрик для LightGBM (упрощенные признаки)...\")\n",
    "    for name, days in horizons.items():\n",
    "        test_horizon = lgbm_results_df[lgbm_results_df['date'] <= min_test_date + pd.Timedelta(days=days-1)]\n",
    "        if test_horizon.empty or test_horizon['item_id'].isnull().all():\n",
    "            print(f\"Предупреждение: Нет данных для горизонта '{name}'.\")\n",
    "            lgbm_results_summary[name] = pd.Series({'MAE': np.nan, 'RMSE': np.nan, 'sMAPE': np.nan, 'R2': np.nan})\n",
    "            continue\n",
    "        try:\n",
    "            horizon_metrics_df = test_horizon.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_lgbm'])))\n",
    "            lgbm_results_summary[name] = horizon_metrics_df.mean()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при расчете метрик для горизонта '{name}': {e}\")\n",
    "            lgbm_results_summary[name] = pd.Series({'MAE': np.nan, 'RMSE': np.nan, 'sMAPE': np.nan, 'R2': np.nan})\n",
    "    lgbm_simplified_summary_df = pd.DataFrame(lgbm_results_summary) # Переприсваиваем\n",
    "else:\n",
    "     print(\"Ошибка: Не удалось получить/декодировать item_id для расчета метрик.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Сводная таблица метрик LightGBM (упрощенные признаки) ---\")\n",
    "print(lgbm_simplified_summary_df)\n",
    "\n",
    "\n",
    "# Дополнительно: Важность признаков\n",
    "try:\n",
    "    print(\"\\n--- Важность признаков LightGBM (упрощенные признаки) ---\")\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': model_lgb_simplified.feature_name_,\n",
    "        'importance': model_lgb_simplified.feature_importances_\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "    print(feature_importance_df.head(20))\n",
    "except Exception as e:\n",
    "    print(f\"Не удалось получить важность признаков: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469b7a4",
   "metadata": {},
   "source": [
    "### Подбор параметров LBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ручной подбор параметров (Grid Search) для LightGBM (упрощенные признаки) ---\n",
      "Всего комбинаций для перебора: 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc794dd0dbd423493e449cf93af3430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid Search Progress:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n"
     ]
    }
   ],
   "source": [
    "# Ручной подбор параметров LGBM - Упрощенные признаки\n",
    "print(\"--- Ручной подбор параметров (Grid Search) для LightGBM (упрощенные признаки) ---\")\n",
    "\n",
    "# --- Определяем сетку параметров ---\n",
    "param_grid = {\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'learning_rate': [0.02, 0.05, 0.1],\n",
    "    'feature_fraction': [0.7, 0.8, 0.9],\n",
    "    'bagging_fraction': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# Фиксированные параметры\n",
    "base_params = {\n",
    "    'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 2000,\n",
    "    'bagging_freq': 1, 'verbose': -1, 'n_jobs': -1, 'seed': 42,\n",
    "    'boosting_type': 'gbdt',\n",
    "}\n",
    "early_stopping_rounds = 50\n",
    "\n",
    "# --- Перебор параметров ---\n",
    "results = []\n",
    "best_mae = np.inf\n",
    "best_params = {}\n",
    "best_iteration = 0\n",
    "\n",
    "keys, values = zip(*param_grid.items())\n",
    "param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "print(f\"Всего комбинаций для перебора: {len(param_combinations)}\")\n",
    "\n",
    "start_grid_search_time = time.time()\n",
    "\n",
    "for params_combo in tqdm(param_combinations, desc=\"Grid Search Progress\"):\n",
    "    current_params = base_params.copy()\n",
    "    current_params.update(params_combo)\n",
    "    try:\n",
    "        model_lgb_gs = lgb.LGBMRegressor(**current_params)\n",
    "        model_lgb_gs.fit(X_train, y_train,\n",
    "                         eval_set=[(X_test, y_test)],\n",
    "                         eval_metric='mae',\n",
    "                         callbacks=[lgb.early_stopping(stopping_rounds=early_stopping_rounds, verbose=False)],\n",
    "                         categorical_feature=CATEGORICAL_FEATURES)\n",
    "\n",
    "        current_best_iter = model_lgb_gs.best_iteration_ if model_lgb_gs.best_iteration_ is not None else current_params['n_estimators']\n",
    "        if current_best_iter is None or current_best_iter <= 0: current_best_iter = 1 # Ensure positive iteration\n",
    "        y_pred_gs = model_lgb_gs.predict(X_test, num_iteration=current_best_iter)\n",
    "        y_pred_gs = np.maximum(0, y_pred_gs)\n",
    "        mae_score = mean_absolute_error(y_test, y_pred_gs)\n",
    "        results.append({'params': params_combo, 'mae': mae_score, 'best_iteration': current_best_iter})\n",
    "\n",
    "        if mae_score < best_mae:\n",
    "            best_mae = mae_score; best_params = params_combo; best_iteration = current_best_iter\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing combo {params_combo}: {e}\")\n",
    "        results.append({'params': params_combo, 'mae': np.inf, 'best_iteration': None})\n",
    "\n",
    "\n",
    "end_grid_search_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4161a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Grid Search завершен за 121.12 сек. ---\n",
      "Лучшая MAE на тестовом наборе (90 дней): 5.0243\n",
      "Лучшие параметры:\n",
      "{'num_leaves': 15, 'learning_rate': 0.1, 'feature_fraction': 0.8, 'bagging_fraction': 0.9}\n",
      "Лучшее количество итераций: 127\n"
     ]
    }
   ],
   "source": [
    "# выведу отдельно, чтобы скрыть warning'и\n",
    "print(f\"\\n--- Grid Search завершен за {end_grid_search_time - start_grid_search_time:.2f} сек. ---\")\n",
    "print(f\"Лучшая MAE на тестовом наборе (90 дней): {best_mae:.4f}\")\n",
    "print(\"Лучшие параметры:\")\n",
    "print(best_params)\n",
    "print(f\"Лучшее количество итераций: {best_iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d0e0d83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Обучение финальной модели LGBM с лучшими параметрами (упрощенные признаки) ---\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Обучение финальной модели завершено за 0.38 сек.\n",
      "\n",
      "--- Генерация прогнозов финальной модели LightGBM (упрощенные признаки) ---\n",
      "Прогнозирование завершено за 0.00 сек.\n",
      "\n",
      "Расчет метрик для финальной упрощенной модели LightGBM...\n",
      "\n",
      "--- Сводная таблица метрик финальной УПРОЩЕННОЙ модели LightGBM ---\n",
      "            Week      Month    Quarter\n",
      "MAE     3.955409   4.310566   5.024306\n",
      "RMSE    5.019303   5.454778   7.044391\n",
      "sMAPE  69.375718  77.257021  79.240610\n",
      "R2      0.021343   0.023109   0.030771\n",
      "\n",
      "--- Важность признаков финальной УПРОЩЕННОЙ модели LightGBM ---\n",
      "             feature  importance\n",
      "7          dayofyear         367\n",
      "6         weekofyear         250\n",
      "3         sell_price         179\n",
      "19   cnt_roll_std_28         172\n",
      "18  cnt_roll_mean_28         142\n",
      "14   cnt_roll_mean_7         134\n",
      "20   item_id_encoded         100\n",
      "5         dayofmonth          59\n",
      "8          cnt_lag_7          57\n",
      "15    cnt_roll_std_7          56\n",
      "16  cnt_roll_mean_14          42\n",
      "0               wday          38\n",
      "1              month          35\n",
      "17   cnt_roll_std_14          33\n",
      "11        cnt_lag_28          27\n",
      "13        cnt_lag_90          23\n",
      "9         cnt_lag_14          16\n",
      "12        cnt_lag_35          15\n",
      "2               year          15\n",
      "4          dayofweek           9\n"
     ]
    }
   ],
   "source": [
    "# --- Обучение финальной модели с лучшими параметрами ---\n",
    "print(\"\\n--- Обучение финальной модели LGBM с лучшими параметрами (упрощенные признаки) ---\")\n",
    "final_params = base_params.copy()\n",
    "final_params.update(best_params)\n",
    "final_params['n_estimators'] = best_iteration if best_iteration > 0 else 10 # Используем найденное число деревьев\n",
    "if 'metric' in final_params: del final_params['metric'] # Удаляем метрику для финального обучения\n",
    "\n",
    "start_final_fit_time = time.time()\n",
    "model_lgb_final_simplified = lgb.LGBMRegressor(**final_params)\n",
    "# Обучаем на ВСЕХ X_train, y_train с КАТЕГОРИЯМИ\n",
    "model_lgb_final_simplified.fit(X_train, y_train, categorical_feature=CATEGORICAL_FEATURES)\n",
    "end_final_fit_time = time.time()\n",
    "print(f\"Обучение финальной модели завершено за {end_final_fit_time - start_final_fit_time:.2f} сек.\")\n",
    "\n",
    "\n",
    "# --- Прогнозирование и Оценка финальной УПРОЩЕННОЙ модели ---\n",
    "print(\"\\n--- Генерация прогнозов финальной модели LightGBM (упрощенные признаки) ---\")\n",
    "start_predict_time = time.time()\n",
    "# Прогнозируем на X_test\n",
    "y_pred_lgb_final = model_lgb_final_simplified.predict(X_test)\n",
    "y_pred_lgb_final = np.maximum(0, y_pred_lgb_final)\n",
    "end_predict_time = time.time()\n",
    "print(f\"Прогнозирование завершено за {end_predict_time - start_predict_time:.2f} сек.\")\n",
    "\n",
    "# --- Оценка ---\n",
    "# Создаем обратный маппинг для item_id (из хардкода в Ячейке 6.1)\n",
    "item_id_map_reverse = {\n",
    "    0: 'STORE_1_064', 1: 'STORE_1_065', 2: 'STORE_1_090', 3: 'STORE_1_252',\n",
    "    4: 'STORE_1_325', 5: 'STORE_1_339', 6: 'STORE_1_376', 7: 'STORE_1_546',\n",
    "    8: 'STORE_1_547', 9: 'STORE_1_555', 10: 'STORE_1_584', 11: 'STORE_1_586',\n",
    "    12: 'STORE_1_587', 13: 'STORE_1_714', 14: 'STORE_1_727'\n",
    "}\n",
    "\n",
    "# Создаем DataFrame с результатами, используя test_features_df для получения item_id_encoded и date\n",
    "lgbm_final_simplified_results_df = pd.DataFrame({\n",
    "    'date': test_features_df['date'].values,\n",
    "    'item_id_encoded': test_features_df['item_id_encoded'].values, # Закодированный ID\n",
    "    'cnt': y_test.values, # Фактические значения из y_test\n",
    "    'yhat_lgbm_final_simpl': y_pred_lgb_final # Прогнозы\n",
    "})\n",
    "# Добавляем исходный строковый item_id для группировки при оценке\n",
    "lgbm_final_simplified_results_df['item_id'] = lgbm_final_simplified_results_df['item_id_encoded'].map(item_id_map_reverse)\n",
    "\n",
    "# --- Сводная таблица метрик ---\n",
    "lgbm_final_simplified_summary_df = pd.DataFrame() # Инициализация\n",
    "if 'item_id' in lgbm_final_simplified_results_df.columns and not lgbm_final_simplified_results_df['item_id'].isnull().all():\n",
    "    lgbm_results_summary = {}\n",
    "    min_test_date = lgbm_final_simplified_results_df['date'].min()\n",
    "    # Определяем горизонты (можно взять из констант FH_*)\n",
    "    horizons = {'Week': 7, 'Month': 30, 'Quarter': 90}\n",
    "    print(\"\\nРасчет метрик для финальной упрощенной модели LightGBM...\")\n",
    "    for name, days in horizons.items():\n",
    "        test_horizon = lgbm_final_simplified_results_df[lgbm_final_simplified_results_df['date'] <= min_test_date + pd.Timedelta(days=days-1)]\n",
    "        if test_horizon.empty or test_horizon['item_id'].isnull().all():\n",
    "            print(f\"Предупреждение: Нет данных для горизонта '{name}'.\")\n",
    "            lgbm_results_summary[name] = pd.Series({'MAE': np.nan, 'RMSE': np.nan, 'sMAPE': np.nan, 'R2': np.nan})\n",
    "            continue\n",
    "        try:\n",
    "            horizon_metrics_df = test_horizon.groupby('item_id').apply(lambda x: pd.Series(calculate_metrics(x['cnt'], x['yhat_lgbm_final_simpl']))) # Исправлено имя прогноза\n",
    "            lgbm_results_summary[name] = horizon_metrics_df.mean()\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при расчете метрик для горизонта '{name}': {e}\")\n",
    "            lgbm_results_summary[name] = pd.Series({'MAE': np.nan, 'RMSE': np.nan, 'sMAPE': np.nan, 'R2': np.nan})\n",
    "    lgbm_final_simplified_summary_df = pd.DataFrame(lgbm_results_summary)\n",
    "else:\n",
    "     print(\"Ошибка: Не удалось получить/декодировать item_id для расчета метрик.\")\n",
    "\n",
    "print(\"\\n--- Сводная таблица метрик финальной УПРОЩЕННОЙ модели LightGBM ---\")\n",
    "print(lgbm_final_simplified_summary_df)\n",
    "\n",
    "# --- Важность признаков ---\n",
    "try:\n",
    "    print(\"\\n--- Важность признаков финальной УПРОЩЕННОЙ модели LightGBM ---\")\n",
    "    feature_importance_df_final_simpl = pd.DataFrame({\n",
    "        'feature': model_lgb_final_simplified.feature_name_,\n",
    "        'importance': model_lgb_final_simplified.feature_importances_\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "    print(feature_importance_df_final_simpl.head(20))\n",
    "except Exception as e:\n",
    "    print(f\"Не удалось получить важность признаков: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a85ea60",
   "metadata": {},
   "source": [
    "## Итоговые метрики по всем протестированнным моделям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4c8a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Итоговое сравнение моделей: Горизонт - Неделя (Отсортировано по MAE) ---\n",
      "       LGBM_simplified_tuned   Orbit     ETS   TBATS  AutoARIMA  Baseline  Prophet\n",
      "MAE                    3.955   4.064   4.149   4.330      4.621     5.181    5.885\n",
      "RMSE                   5.019   4.828   4.872   4.994      5.298     6.515    6.649\n",
      "sMAPE                 69.376  79.971  76.182  77.680     79.628    69.216   86.743\n",
      "R2                     0.021   0.113   0.098   0.063     -0.020    -0.820   -1.070\n",
      "\n",
      "--- Итоговое сравнение моделей: Горизонт - Месяц (Отсортировано по MAE) ---\n",
      "       LGBM_simplified_tuned   TBATS   Orbit     ETS  AutoARIMA  Prophet  Baseline\n",
      "MAE                    4.311   4.608   4.626   4.785      4.911    5.265     5.696\n",
      "RMSE                   5.455   5.735   5.754   5.833      5.839    6.392     7.372\n",
      "sMAPE                 77.257  76.456  84.786  79.566     81.026   84.176    70.952\n",
      "R2                     0.023   0.012  -0.024   0.076      0.035   -0.302    -0.687\n",
      "\n",
      "--- Итоговое сравнение моделей: Горизонт - Квартал (Отсортировано по MAE) ---\n",
      "       LGBM_simplified_tuned  Prophet   Orbit  AutoARIMA   TBATS     ETS  Baseline\n",
      "MAE                    5.024    6.831   6.898      7.141   7.242   7.284     7.934\n",
      "RMSE                   7.044    8.720   8.906      9.064   8.990   9.310    10.240\n",
      "sMAPE                 79.241   86.461  95.731     85.592  84.911  86.067    78.637\n",
      "R2                     0.031   -0.202  -0.323     -0.073  -0.369  -0.120    -0.658\n"
     ]
    }
   ],
   "source": [
    "# --- Создание ФИНАЛЬНЫХ сводных таблиц сравнения ВСЕХ моделей по горизонтам (отсортировано по MAE) ---\n",
    "\n",
    "# Добавляем результаты финальной модели LGBM к списку\n",
    "# Убедимся, что lgbm_final_summary_df существует\n",
    "if 'lgbm_final_simplified_summary_df' not in locals():\n",
    "     print(\"Ошибка: Не найден DataFrame lgbm_final_simplified_summary_df. Выполните шаг 6.3.\")\n",
    "else:\n",
    "    model_summaries_final = {\n",
    "        'Baseline': 'baseline_summary_df',\n",
    "        'ETS': 'ets_summary_df',\n",
    "        'Prophet': 'prophet_summary_df',\n",
    "        'AutoARIMA': 'autoarima_summary_df',\n",
    "        'TBATS': 'tbats_summary_df',\n",
    "        'Orbit': 'orbit_summary_df',\n",
    "        'LGBM_simplified_tuned': 'lgbm_final_simplified_summary_df' # Добавляем новую модель\n",
    "    }\n",
    "\n",
    "    # Проверяем наличие всех DataFrame'ов\n",
    "    missing_dfs_final = []\n",
    "    for df_name in model_summaries_final.values():\n",
    "        if df_name not in locals():\n",
    "            missing_dfs_final.append(df_name)\n",
    "\n",
    "    if missing_dfs_final:\n",
    "        print(f\"Ошибка: Не найдены DataFrame'ы: {', '.join(missing_dfs_final)}\")\n",
    "    else:\n",
    "        # --- Таблица для Недельного горизонта (FH=7) ---\n",
    "        week_metrics_list_final = {}\n",
    "        for model_name, df_name in model_summaries_final.items():\n",
    "            df = locals()[df_name]\n",
    "            if 'Week' in df.columns and not df['Week'].isnull().all(): # Добавлена проверка на NaN\n",
    "                week_metrics_list_final[model_name] = df['Week']\n",
    "            else:\n",
    "                print(f\"Предупреждение: Данные для 'Week' отсутствуют или содержат NaN в {df_name}\")\n",
    "\n",
    "        # Проверяем, есть ли что конкатенировать\n",
    "        if week_metrics_list_final:\n",
    "             metrics_week_comparison_final = pd.concat(week_metrics_list_final, axis=1)\n",
    "             # Сортируем по MAE\n",
    "             metrics_week_final_sorted = metrics_week_comparison_final.sort_values(by='MAE', axis=1)\n",
    "             print(\"\\n--- Итоговое сравнение моделей: Горизонт - Неделя (Отсортировано по MAE) ---\")\n",
    "             print(metrics_week_final_sorted.round(3))\n",
    "        else:\n",
    "            print(\"\\nНедостаточно данных для сравнения моделей на недельном горизонте.\")\n",
    "\n",
    "\n",
    "        # --- Таблица для Месячного горизонта (FH=30) ---\n",
    "        month_metrics_list_final = {}\n",
    "        for model_name, df_name in model_summaries_final.items():\n",
    "            df = locals()[df_name]\n",
    "            if 'Month' in df.columns and not df['Month'].isnull().all():\n",
    "                month_metrics_list_final[model_name] = df['Month']\n",
    "            else:\n",
    "                print(f\"Предупреждение: Данные для 'Month' отсутствуют или содержат NaN в {df_name}\")\n",
    "\n",
    "        if month_metrics_list_final:\n",
    "            metrics_month_comparison_final = pd.concat(month_metrics_list_final, axis=1)\n",
    "            metrics_month_final_sorted = metrics_month_comparison_final.sort_values(by='MAE', axis=1)\n",
    "            print(\"\\n--- Итоговое сравнение моделей: Горизонт - Месяц (Отсортировано по MAE) ---\")\n",
    "            print(metrics_month_final_sorted.round(3))\n",
    "        else:\n",
    "            print(\"\\nНедостаточно данных для сравнения моделей на месячном горизонте.\")\n",
    "\n",
    "\n",
    "        # --- Таблица для Квартального горизонта (FH=90) ---\n",
    "        quarter_metrics_list_final = {}\n",
    "        for model_name, df_name in model_summaries_final.items():\n",
    "            df = locals()[df_name]\n",
    "            if 'Quarter' in df.columns and not df['Quarter'].isnull().all():\n",
    "                quarter_metrics_list_final[model_name] = df['Quarter']\n",
    "            else:\n",
    "                print(f\"Предупреждение: Данные для 'Quarter' отсутствуют или содержат NaN в {df_name}\")\n",
    "\n",
    "        if quarter_metrics_list_final:\n",
    "            metrics_quarter_comparison_final = pd.concat(quarter_metrics_list_final, axis=1)\n",
    "            metrics_quarter_final_sorted = metrics_quarter_comparison_final.sort_values(by='MAE', axis=1)\n",
    "            print(\"\\n--- Итоговое сравнение моделей: Горизонт - Квартал (Отсортировано по MAE) ---\")\n",
    "            print(metrics_quarter_final_sorted.round(3))\n",
    "        else:\n",
    "             print(\"\\nНедостаточно данных для сравнения моделей на квартальном горизонте.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eaa75f",
   "metadata": {},
   "source": [
    "## Сохранение результатов и моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Сохранение сводных таблиц метрик в 'results/' ---\n",
      "Таблица для горизонта 'week' сохранена в: results/comparison_metrics_week_sorted.csv\n",
      "Таблица для горизонта 'month' сохранена в: results/comparison_metrics_month_sorted.csv\n",
      "Таблица для горизонта 'quarter' сохранена в: results/comparison_metrics_quarter_sorted.csv\n"
     ]
    }
   ],
   "source": [
    "# Сохранение сводных таблиц метрик\n",
    "# Директория для сохранения результатов\n",
    "results_dir = 'results'\n",
    "os.makedirs(results_dir, exist_ok=True) # Создаем директорию, если её нет\n",
    "\n",
    "# Словарь с таблицами для сохранения\n",
    "metrics_tables_to_save = {\n",
    "    'week': 'metrics_week_final_sorted',\n",
    "    'month': 'metrics_month_final_sorted',\n",
    "    'quarter': 'metrics_quarter_final_sorted'\n",
    "}\n",
    "\n",
    "print(f\"\\n--- Сохранение сводных таблиц метрик в '{results_dir}/' ---\")\n",
    "\n",
    "for horizon, df_name in metrics_tables_to_save.items():\n",
    "    try:\n",
    "        # Получаем DataFrame по его имени из локальных переменных\n",
    "        df_to_save = locals()[df_name]\n",
    "        if isinstance(df_to_save, pd.DataFrame):\n",
    "            filepath = os.path.join(results_dir, f'comparison_metrics_{horizon}_sorted.csv')\n",
    "            df_to_save.to_csv(filepath)\n",
    "            print(f\"Таблица для горизонта '{horizon}' сохранена в: {filepath}\")\n",
    "        else:\n",
    "            print(f\"Переменная {df_name} не является DataFrame, пропуск.\")\n",
    "    except KeyError:\n",
    "        print(f\"Ошибка: DataFrame '{df_name}' не найден. Не могу сохранить метрики для '{horizon}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при сохранении метрик для '{horizon}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Сохранение обученных моделей в 'models/' ---\n",
      "Модель(и) 'ets' сохранена в: models/ets.joblib\n",
      "Модель(и) 'prophet' сохранена в: models/prophet.joblib\n",
      "Модель(и) 'tbats' сохранена в: models/tbats.joblib\n",
      "Модель(и) 'orbit' сохранена в: models/orbit.joblib\n",
      "Модель(и) 'lgb_final_simplified' сохранена в: models/lgb_final_simplified.joblib\n",
      "Модель LGBM также сохранена в нативном формате: models/model_lgb_final_simplified.txt\n"
     ]
    }
   ],
   "source": [
    "# Сохранение обученных моделей\n",
    "\n",
    "# Директория для сохранения моделей\n",
    "models_dir = 'models'\n",
    "os.makedirs(models_dir, exist_ok=True) # Создаем директорию\n",
    "\n",
    "# Список моделей/словарей для сохранения\n",
    "models_to_save = {\n",
    "    'ets': 'ets_models',\n",
    "    'prophet': 'prophet_models',\n",
    "    # 'autoarima': 'autoarima_models', АвтоАриму не сохраняем, т.к. файл получается ~1 ГБ\n",
    "    'tbats': 'tbats_models',\n",
    "    'orbit': 'orbit_models',\n",
    "    'lgb_final_simplified': 'model_lgb_final_simplified'\n",
    "}\n",
    "\n",
    "print(f\"\\n--- Сохранение обученных моделей в '{models_dir}/' ---\")\n",
    "\n",
    "for model_key, model_var_name in models_to_save.items():\n",
    "    try:\n",
    "        model_object = locals()[model_var_name]\n",
    "        if model_object is not None:\n",
    "            filepath = os.path.join(models_dir, f'{model_key}.joblib')\n",
    "            joblib.dump(model_object, filepath)\n",
    "            print(f\"Модель(и) '{model_key}' сохранена в: {filepath}\")\n",
    "        else:\n",
    "             print(f\"Объект '{model_var_name}' равен None, пропуск сохранения.\")\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"Ошибка: Объект '{model_var_name}' не найден. Не могу сохранить модель '{model_key}'.\")\n",
    "    except Exception as e:\n",
    "        # Обработка возможных ошибок сериализации (особенно для Prophet/Orbit)\n",
    "        print(f\"(!) Ошибка при сохранении модели '{model_key}': {e}\")\n",
    "        print(f\"    Модели Prophet/Orbit могут иметь проблемы с сериализацией.\")\n",
    "\n",
    "# Особое примечание для LightGBM:\n",
    "# Модели LightGBM также можно сохранять собственным методом save_model,\n",
    "# который создает текстовый файл, более устойчивый к изменениям версий.\n",
    "try:\n",
    "    if 'model_lgb_final_simplified' in locals() and model_lgb_final_simplified is not None:\n",
    "        lgbm_native_path = os.path.join(models_dir, 'model_lgb_final_simplified.txt')\n",
    "        model_lgb_final_simplified.booster_.save_model(lgbm_native_path)\n",
    "        print(f\"Модель LGBM также сохранена в нативном формате: {lgbm_native_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при сохранении LGBM в нативном формате: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309c6ef",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30327b04",
   "metadata": {},
   "source": [
    "Отличная работа! Мы прошли долгий путь от анализа данных до обучения, сравнения и оптимизации нескольких моделей. Давайте подведем итоги и сделаем финальные выводы.\n",
    "\n",
    "**Резюме процесса:**\n",
    "\n",
    "1.  **EDA:** Глубоко изучили данные `STORE_1`, выявили тренды, сильную недельную сезонность, влияние праздников (которое, как оказалось позже, хорошо кодируется календарными признаками), нестационарность рядов и остаточную автокорреляцию после простой декомпозиции. Обработали пропуски.\n",
    "2.  **Подготовка:** Разделили данные на обучающий и 90-дневный тестовый наборы. Определили метрики (MAE, RMSE, sMAPE, R2).\n",
    "3.  **Моделирование (Этап 1 - Широкий поиск):**\n",
    "    *   Создали `Baseline` (сезонный наивный).\n",
    "    *   Обучили статистические модели: `ETS`, `AutoARIMA`, `TBATS`.\n",
    "    *   Обучили модели с регрессорами: `Prophet`, `Orbit (DLT)`.\n",
    "    *   Обучили ML модель: `LightGBM` с обширным набором признаков (календарные, лаги, окна, события, цена, ID товара и т.д.).\n",
    "4.  **Сравнение (Этап 1):** Сравнили все модели на горизонтах неделя/месяц/квартал. LightGBM показал очень хорошие результаты по MAE/RMSE, но высокий sMAPE. ETS, TBATS, Orbit были конкурентоспособны на коротких горизонтах. Prophet выделился на квартальном горизонте (но все равно уступал LGBM).\n",
    "5.  **Оптимизация LGBM (Этап 2):**\n",
    "    *   Проанализировали важность признаков для LGBM. Обнаружили, что явные признаки событий почти не используются, а `dayofyear`, `weekofyear`, `dayofmonth` доминируют. `item_id`, лаги, окна и цена также важны. `month` и `cashback` оказались неважными.\n",
    "    *   **Упростили Feature Engineering:** Удалили признаки событий, `month`, `cashback`. Заменили `LabelEncoder` для `item_id` на извлечение последних 3 цифр (создав `item_id_numeric`) и решили **считать его категориальным признаком** для LGBM (т.к. коды 0-14 теперь плотные).\n",
    "    *   **Подобрали параметры:** Выполнили Grid Search для `num_leaves`, `learning_rate`, `feature_fraction`, `bagging_fraction`, найдя оптимальные значения и количество итераций (`n_estimators=57`).\n",
    "    *   Обучили финальную **`LGBM_simplified_tuned`**.\n",
    "6.  **Финальное сравнение:** Сравнили все исходные модели с финальной оптимизированной моделью LGBM.\n",
    "7.  **Разработка класса:** Реализовали класс `DemandForecasterLGBM`, инкапсулирующий упрощенный процесс создания признаков, обучения, сохранения/загрузки необходимых компонентов (модель, фичи, категории, история, события) и прогнозирования на новых данных. Прошли через несколько итераций отладки класса.\n",
    "\n",
    "**Анализ итоговых результатов:**\n",
    "\n",
    "1.  **Лидерство `LGBM_simplified_tuned`:** Финальная, оптимизированная и упрощенная модель LightGBM стала **абсолютным лидером по MAE и RMSE на всех трех горизонтах**.\n",
    "    *   **Неделя:** MAE 3.955 (лучший).\n",
    "    *   **Месяц:** MAE 4.311 (лучший, со значительным отрывом).\n",
    "    *   **Квартал:** MAE 5.024 (лучший, с огромным отрывом от следующего - Prophet с 6.831).\n",
    "2.  **Улучшение sMAPE для LGBM:** Упрощение признаков и, возможно, использование плотных кодов для `item_id` **резко улучшили sMAPE** для LightGBM. Теперь он показывает лучший или второй лучший sMAPE на всех горизонтах (69.4 на неделе, 77.3 на месяце, 79.2 на квартале), уступая только `Baseline`. Это решает основную проблему предыдущей версии LGBM.\n",
    "3.  **R2:** Упрощенный LGBM показывает **положительный R2** на всех горизонтах (хотя и небольшой: 0.021, 0.023, 0.031). Это единственная модель, которая стабильно лучше константного прогноза среднего на всех периодах, включая квартальный.\n",
    "4.  **Другие модели:**\n",
    "    *   `Orbit` и `ETS` остаются сильными конкурентами на недельном горизонте по MAE/RMSE, но уступают на более длинных.\n",
    "    *   `TBATS` хорошо показал себя на месячном горизонте (второе место по MAE после LGBM).\n",
    "    *   `Prophet` интересен тем, что стал вторым по MAE на квартальном горизонте, но все равно значительно хуже LGBM.\n",
    "    *   `AutoARIMA` показала средние результаты.\n",
    "    *   `Baseline` подтвердил свою роль - худший по абсолютным метрикам, но часто лучший по sMAPE.\n",
    "\n",
    "**Финальные выводы:**\n",
    "\n",
    "1.  **Лучшая модель:** Для данной задачи и данных **оптимизированная модель LightGBM с упрощенным набором признаков (`LGBM_simplified_tuned`) является наилучшим выбором**. Она обеспечивает самую высокую точность по абсолютным ошибкам (MAE/RMSE) на всех горизонтах и имеет конкурентоспособную относительную ошибку (sMAPE), а также высокую скорость обучения и прогнозирования.\n",
    "2.  **Ценность Feature Engineering и Оптимизации:** Процесс показал, что:\n",
    "    *   Создание релевантных признаков (календарные, лаги, окна, цена, ID товара) критически важно для успеха ML-моделей.\n",
    "    *   Анализ важности признаков позволяет **упростить модель**, убрав избыточные или неважные фичи (как признаки событий), что может **улучшить** не только интерпретируемость, но и некоторые метрики (как sMAPE в нашем случае) и скорость.\n",
    "    *   Подбор гиперпараметров (даже простой Grid Search) может дать дополнительный прирост качества.\n",
    "3.  **Кодирование ID:** Использование простого числового ID (0-14) и указание его как категориального признака для LGBM сработало хорошо и убрало соответствующие предупреждения.\n",
    "4.  **Горизонт прогнозирования:** Точность прогноза ожидаемо падает с увеличением горизонта. Долгосрочное (квартал) прогнозирование остается сложной задачей с низкой общей предсказуемостью (низкий R2).\n",
    "5.  **Класс для инференса:** Создание класса потребовало тщательной проработки логики сохранения/загрузки состояния модели и обработки входных данных на этапе `predict` (особенно расчета лаговых признаков с использованием сохраненной истории).\n",
    "\n",
    "Таким образом, итоговым решением является использование **финальной модели LightGBM**, обученной на упрощенном наборе признаков с оптимальными параметрами, инкапсулированной в класс `DemandForecasterLGBM` для удобства использования и инференса."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
